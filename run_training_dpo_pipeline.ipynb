{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Training Pipeline\n",
    "[run_training_dpo_pipeline.ipynb](https://github.com/shibing624/MedicalGPT/blob/main/run_training_dpo_pipeline.ipynb)    | [Open In Colab](https://colab.research.google.com/github/shibing624/MedicalGPT/blob/main/run_training_dpo_pipeline.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stage 1: Continue Pretraining\n",
    "\n",
    "第一阶段：PT(Continue PreTraining)增量预训练，在海量领域文本数据上二次预训练GPT模型，以适配领域数据分布\n",
    "\n",
    "注意：\n",
    "1. 此阶段是可选的，如果你没有海量领域文本，可以跳过此阶段，直接进行SFT阶段的有监督微调\n",
    "2. 我实验发现：做领域知识注入，SFT比PT更高效，也可以跳过PT阶段\n",
    "\n",
    "| Stage 1: Continue Pretraining   |  [pretraining.py](https://github.com/shibing624/MedicalGPT/blob/main/pretraining.py) | [run_pt.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_pt.sh)    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 说明：\n",
    "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
    "\n",
    "1. 生成模型：使用的是Bloom的`bigscience/bloomz-560m`\n",
    "2. 数据集：PT阶段使用的是中文天龙八部小说部分文本和英文书籍部分文本，位于`data/pretrain`文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置运行环境\n",
    "\n",
    "本地执行可注释以下配置环境的命令，colab执行要打开注释，用于配置环境\n",
    "\n",
    "colab建议使用T4 GPU训练，设置方式：`代码执行程序 -> 更改运行时类型 -> 运行时类型：Python3，硬件加速器：GPU，GPU类型：T4 -> 保存`\n",
    "\n",
    "步骤：\n",
    "1. 下载最新代码到本地\n",
    "2. 安装依赖包\n",
    "\n",
    "依赖包如下，保证最新版本：\n",
    "\n",
    "```\n",
    "loguru\n",
    "transformers\n",
    "sentencepiece\n",
    "datasets\n",
    "tensorboard\n",
    "tqdm\n",
    "peft\n",
    "trl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_domain_tokenizer.py\t   merge_peft_adapter.py\n",
      "chatpdf.py\t\t\t   merge_tokenizers.py\n",
      "CITATION.cff\t\t\t   ppo_training.py\n",
      "_config.yml\t\t\t   pretraining.py\n",
      "CONTRIBUTING.md\t\t\t   README_EN.md\n",
      "convert_dataset.py\t\t   README.md\n",
      "data\t\t\t\t   requirements.txt\n",
      "deepspeed_zero_stage2_config.json  reward_modeling.py\n",
      "deepspeed_zero_stage3_config.json  run_dpo.sh\n",
      "DISCLAIMER\t\t\t   run_ppo.sh\n",
      "docs\t\t\t\t   run_pt.sh\n",
      "dpo_training.py\t\t\t   run_rm.sh\n",
      "fastapi_server_demo.py\t\t   run_sft.sh\n",
      "gradio_demo.py\t\t\t   run_training_dpo_pipeline.ipynb\n",
      "inference_multigpu_demo.py\t   run_training_ppo_pipeline.ipynb\n",
      "inference.py\t\t\t   supervised_finetuning.py\n",
      "LICENSE\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone --depth 1 https://github.com/shibing624/MedicalGPT.git\n",
    "# %cd MedicalGPT\n",
    "# %ls\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage1 咱们开始吧\n",
    "\n",
    "训练步骤如下：\n",
    "\n",
    "1. 确认训练集\n",
    "2. 执行训练脚本\n",
    "\n",
    "训练脚本的执行逻辑如下：\n",
    "1. 导入依赖包\n",
    "2. 设置参数\n",
    "3. 定义各函数并加载训练集\n",
    "4. 加载模型和tokenizer\n",
    "5. 开始训练并评估\n",
    "6. 查看训练结果\n",
    "\n",
    "**以下参数可以根据你的GPU实际情况修改，当前参数是根据Colab的T4单卡GPU（16GB显存）配置的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_article_tail500.txt  fever.txt  tianlongbabu.txt\n"
     ]
    }
   ],
   "source": [
    "%ls ./data/pretrain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-14 11:02:42.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mModel args: ModelArguments(model_type='baichuan', model_name_or_path='/data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat', tokenizer_name_or_path=None, load_in_8bit=False, load_in_4bit=False, cache_dir=None, model_revision='main', hf_hub_token=None, use_fast_tokenizer=False, torch_dtype='float16', device_map='auto', trust_remote_code=True)\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:42.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m379\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/pretrain', validation_file_dir='./data/pretrain', max_train_samples=20000, max_eval_samples=10, streaming=False, block_size=128, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=1, keep_linebreaks=True)\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:42.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mTraining args: Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=False,\n",
      "ddp_timeout=30000,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=steps,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=True,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0002,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=outputs-pt-v1/runs/Mar14_11-02-42_sg-gpt-01.tc-bj7.songguo7.com,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=outputs-pt-v1,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=3,\n",
      "per_device_train_batch_size=3,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=outputs-pt-v1,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.05,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:42.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, qlora=False)\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:42.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:42.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m492\u001b[0m - \u001b[1mtrain files: ['./data/pretrain/en_article_tail500.txt', './data/pretrain/fever.txt', './data/pretrain/tianlongbabu.txt']\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:42.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m502\u001b[0m - \u001b[1meval files: ['./data/pretrain/en_article_tail500.txt', './data/pretrain/fever.txt', './data/pretrain/tianlongbabu.txt']\u001b[0m\n",
      "Generating train split: 3876 examples [00:00, 295213.68 examples/s]\n",
      "Generating validation split: 3876 examples [00:00, 416187.66 examples/s]\n",
      "\u001b[32m2024-03-14 11:02:43.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m534\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 3876\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 3876\n",
      "    })\n",
      "})\u001b[0m\n",
      "Running tokenizer on dataset: 100%|█| 3876/3876 [00:01<00:00, 3794.27 examples/s\n",
      "Running tokenizer on dataset: 100%|█| 3876/3876 [00:01<00:00, 3803.38 examples/s\n",
      "Grouping texts in chunks of 128: 100%|█| 3876/3876 [00:00<00:00, 10410.50 exampl\n",
      "Grouping texts in chunks of 128: 100%|█| 3876/3876 [00:00<00:00, 10416.48 exampl\n",
      "\u001b[32m2024-03-14 11:02:46.326\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m597\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 2378\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:46.326\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m598\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:46.330\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m599\u001b[0m - \u001b[34m\u001b[1mcontract to work in specified mines and mills. There seemed to be no\n",
      "limit to the factories, forges, refineries, and railways that could be\n",
      "built, to the multitudes that could be employed in conquering a\n",
      "continent. As for the future, that was in the hands of Providence!\n",
      "\n",
      "=Business Theories of Politics.=--As the statesmen of Hamilton's school\n",
      "and the planters of Calhoun's had their theories of government and\n",
      "politics, so the leaders in business enterprise had theirs. It was\n",
      "simple and easily stated. \"It is the\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:46.331\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m611\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:46.331\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m612\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:46.334\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m613\u001b[0m - \u001b[34m\u001b[1mcontract to work in specified mines and mills. There seemed to be no\n",
      "limit to the factories, forges, refineries, and railways that could be\n",
      "built, to the multitudes that could be employed in conquering a\n",
      "continent. As for the future, that was in the hands of Providence!\n",
      "\n",
      "=Business Theories of Politics.=--As the statesmen of Hamilton's school\n",
      "and the planters of Calhoun's had their theories of government and\n",
      "politics, so the leaders in business enterprise had theirs. It was\n",
      "simple and easily stated. \"It is the\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:53.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m672\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:53.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m677\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:53.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m690\u001b[0m - \u001b[1mPeft target_modules: ['W_pack', 'down_proj', 'gate_proj', 'o_proj', 'up_proj']\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:53.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m691\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
      "trainable params: 17,891,328 || all params: 7,523,864,576 || trainable%: 0.23779439168895536\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[32m2024-03-14 11:02:54.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m736\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
      "\u001b[32m2024-03-14 11:02:54.666\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m737\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids': tensor([[92333, 23530, 92529,    68, 92361, 93334, 95128, 92720, 92499,    70,\n",
      "         92360,  4506,    65, 93782, 93101, 93551,    67, 92885, 94563,    65,\n",
      "         92430,  7983,    65, 22335, 92665, 82000,    66, 92361,     5, 92885,\n",
      "         93930, 92499,    70, 92360,  6461, 92430, 11817,    65, 92620, 47727,\n",
      "         92885, 94563,    65, 92836, 47727, 20577,    66, 23357, 18911, 92681,\n",
      "         16992, 93325, 94836, 92488,  5075, 93021,    65,  8897, 10358,  9487,\n",
      "            66, 94861, 53351,    65, 94807, 93086, 92979,    89, 93883, 94342,\n",
      "         96633,    65, 96977, 93891, 94202,    89, 92844, 92364, 93484,    65,\n",
      "         94872, 92364, 92858,    89, 92819, 92382, 93348,    65, 97056, 92421,\n",
      "         92979,    66, 92361, 93334, 95128, 92720, 93001, 92982, 93127, 56956,\n",
      "            65, 38330,    70, 92360, 92516, 96633, 35839, 92333,    65, 27402,\n",
      "            68, 92361, 92885, 93930, 92499,    70, 92360, 92390, 34012, 18911,\n",
      "         15936,    66, 92386, 92557, 18911, 57595,    65,  9540],\n",
      "        [92909, 95433, 92894, 92573, 94133, 92355, 23004,    65, 92350, 92467,\n",
      "         22302, 66441, 92366, 94071, 93238, 92831,  7057, 93301, 93815,    66,\n",
      "             5, 92733, 92638, 92442, 92559, 92393,    65, 95365, 87833,    65,\n",
      "         29615, 93518, 93147,  9471, 94013, 92350, 93424,    65, 16563,  2855,\n",
      "         92348, 25684,    65, 92733, 38735, 93514,    65, 93410, 92499,    70,\n",
      "         92360, 92430,  2304, 92430, 14101,     5, 66262, 92898, 41544, 92393,\n",
      "            65, 19974, 70959,    65, 93410, 92499,    70, 92360, 95128, 93786,\n",
      "            65, 21708,  3021,    68, 92361, 15767, 92364, 47666,  9303,    65,\n",
      "          6041, 36012, 92885, 93930,    66,     5, 93334, 95128, 92720, 92355,\n",
      "         23239, 92364, 95709, 92776, 92440, 94563,    65, 19064, 92466,  5376,\n",
      "         11185, 92433, 70039, 33073,    65, 94648, 92538,  9122,    65, 92847,\n",
      "         16153, 46025,    66, 93049, 93518, 92364, 53144, 78122,    65, 92885,\n",
      "         93930, 80920, 92776, 92733, 28199, 94526, 92755,    65],\n",
      "        [92593,  6119,    65, 11732, 93112, 93197, 73905,    66,  4161,  6392,\n",
      "          7829, 65921,  2693,  2702,    65, 92467, 50117,    69, 92755, 94789,\n",
      "            69, 65591, 10089, 92457,    66, 92349, 93535, 92511,  3533, 97923,\n",
      "          2841, 53615, 93760,    69,  5670, 92511, 17629, 92333, 14380, 93760,\n",
      "         92524,  4069, 64423, 97905, 92411,  3887, 49974,    69, 38856, 92462,\n",
      "            69, 23424, 92462,    69, 93700, 92891, 39766, 92456,    69, 94370,\n",
      "         92572, 94465, 95180, 93516, 92457,    66,     5, 92369,    72, 93840,\n",
      "         93287,  3887, 92593, 55850, 45770, 73260, 92725, 94571,  4584,    65,\n",
      "         92467, 92833, 94983,    69, 92348, 93546,    69, 94149, 93758,    69,\n",
      "         92755, 99339,    69, 93564, 97770, 92385, 96303, 95286, 92457,    65,\n",
      "         92441, 59652, 92380, 92732, 55850, 92695, 92649, 53523, 92485,    65,\n",
      "         92411,  3855,  4140, 95862, 93262,    69, 65591, 94084, 94939, 44838,\n",
      "            69,  2722, 92511, 94084, 94939, 44838,    69, 93128]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([[92333, 23530, 92529,    68, 92361, 93334, 95128, 92720, 92499,    70,\n",
      "         92360,  4506,    65, 93782, 93101, 93551,    67, 92885, 94563,    65,\n",
      "         92430,  7983,    65, 22335, 92665, 82000,    66, 92361,     5, 92885,\n",
      "         93930, 92499,    70, 92360,  6461, 92430, 11817,    65, 92620, 47727,\n",
      "         92885, 94563,    65, 92836, 47727, 20577,    66, 23357, 18911, 92681,\n",
      "         16992, 93325, 94836, 92488,  5075, 93021,    65,  8897, 10358,  9487,\n",
      "            66, 94861, 53351,    65, 94807, 93086, 92979,    89, 93883, 94342,\n",
      "         96633,    65, 96977, 93891, 94202,    89, 92844, 92364, 93484,    65,\n",
      "         94872, 92364, 92858,    89, 92819, 92382, 93348,    65, 97056, 92421,\n",
      "         92979,    66, 92361, 93334, 95128, 92720, 93001, 92982, 93127, 56956,\n",
      "            65, 38330,    70, 92360, 92516, 96633, 35839, 92333,    65, 27402,\n",
      "            68, 92361, 92885, 93930, 92499,    70, 92360, 92390, 34012, 18911,\n",
      "         15936,    66, 92386, 92557, 18911, 57595,    65,  9540],\n",
      "        [92909, 95433, 92894, 92573, 94133, 92355, 23004,    65, 92350, 92467,\n",
      "         22302, 66441, 92366, 94071, 93238, 92831,  7057, 93301, 93815,    66,\n",
      "             5, 92733, 92638, 92442, 92559, 92393,    65, 95365, 87833,    65,\n",
      "         29615, 93518, 93147,  9471, 94013, 92350, 93424,    65, 16563,  2855,\n",
      "         92348, 25684,    65, 92733, 38735, 93514,    65, 93410, 92499,    70,\n",
      "         92360, 92430,  2304, 92430, 14101,     5, 66262, 92898, 41544, 92393,\n",
      "            65, 19974, 70959,    65, 93410, 92499,    70, 92360, 95128, 93786,\n",
      "            65, 21708,  3021,    68, 92361, 15767, 92364, 47666,  9303,    65,\n",
      "          6041, 36012, 92885, 93930,    66,     5, 93334, 95128, 92720, 92355,\n",
      "         23239, 92364, 95709, 92776, 92440, 94563,    65, 19064, 92466,  5376,\n",
      "         11185, 92433, 70039, 33073,    65, 94648, 92538,  9122,    65, 92847,\n",
      "         16153, 46025,    66, 93049, 93518, 92364, 53144, 78122,    65, 92885,\n",
      "         93930, 80920, 92776, 92733, 28199, 94526, 92755,    65],\n",
      "        [92593,  6119,    65, 11732, 93112, 93197, 73905,    66,  4161,  6392,\n",
      "          7829, 65921,  2693,  2702,    65, 92467, 50117,    69, 92755, 94789,\n",
      "            69, 65591, 10089, 92457,    66, 92349, 93535, 92511,  3533, 97923,\n",
      "          2841, 53615, 93760,    69,  5670, 92511, 17629, 92333, 14380, 93760,\n",
      "         92524,  4069, 64423, 97905, 92411,  3887, 49974,    69, 38856, 92462,\n",
      "            69, 23424, 92462,    69, 93700, 92891, 39766, 92456,    69, 94370,\n",
      "         92572, 94465, 95180, 93516, 92457,    66,     5, 92369,    72, 93840,\n",
      "         93287,  3887, 92593, 55850, 45770, 73260, 92725, 94571,  4584,    65,\n",
      "         92467, 92833, 94983,    69, 92348, 93546,    69, 94149, 93758,    69,\n",
      "         92755, 99339,    69, 93564, 97770, 92385, 96303, 95286, 92457,    65,\n",
      "         92441, 59652, 92380, 92732, 55850, 92695, 92649, 53523, 92485,    65,\n",
      "         92411,  3855,  4140, 95862, 93262,    69, 65591, 94084, 94939, 44838,\n",
      "            69,  2722, 92511, 94084, 94939, 44838,    69, 93128]],\n",
      "       device='cuda:0')}\u001b[0m\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "  0%|                                                   | 0/793 [00:00<?, ?it/s]/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3352, 'grad_norm': 1.6129279136657715, 'learning_rate': 5e-06, 'epoch': 0.0}\n",
      "{'loss': 3.6319, 'grad_norm': 1.8635456562042236, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4713, 'grad_norm': 2.019843816757202, 'learning_rate': 9.5e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2009, 'grad_norm': 1.763068675994873, 'learning_rate': 0.000145, 'epoch': 0.04}\n",
      "{'loss': 3.0832, 'grad_norm': 1.6203889846801758, 'learning_rate': 0.000195, 'epoch': 0.05}\n",
      "{'loss': 2.8988, 'grad_norm': 1.7962137460708618, 'learning_rate': 0.00019760956175298805, 'epoch': 0.06}\n",
      "  6%|██▋                                       | 50/793 [00:21<05:07,  2.42it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.771605968475342, 'eval_accuracy': 0.4566929133858268, 'eval_runtime': 0.4768, 'eval_samples_per_second': 20.973, 'eval_steps_per_second': 8.389, 'epoch': 0.06}\n",
      "  6%|██▋                                       | 50/793 [00:22<05:07,  2.42it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.47it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.9302, 'grad_norm': 1.6267327070236206, 'learning_rate': 0.0001949535192563081, 'epoch': 0.08}\n",
      "{'loss': 2.9501, 'grad_norm': 1.7563704252243042, 'learning_rate': 0.00019229747675962816, 'epoch': 0.09}\n",
      "{'loss': 2.8372, 'grad_norm': 1.5018967390060425, 'learning_rate': 0.00018964143426294822, 'epoch': 0.1}\n",
      "{'loss': 2.9055, 'grad_norm': 1.7495613098144531, 'learning_rate': 0.00018698539176626827, 'epoch': 0.11}\n",
      "{'loss': 2.8932, 'grad_norm': 1.3655470609664917, 'learning_rate': 0.00018432934926958832, 'epoch': 0.13}\n",
      " 13%|█████▏                                   | 100/793 [00:42<04:47,  2.41it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.50it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.728698253631592, 'eval_accuracy': 0.46141732283464565, 'eval_runtime': 0.4586, 'eval_samples_per_second': 21.806, 'eval_steps_per_second': 8.722, 'epoch': 0.13}\n",
      " 13%|█████▏                                   | 100/793 [00:43<04:47,  2.41it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.92it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.8174, 'grad_norm': 1.060701608657837, 'learning_rate': 0.00018167330677290838, 'epoch': 0.14}\n",
      "{'loss': 2.8319, 'grad_norm': 1.5126104354858398, 'learning_rate': 0.00017901726427622843, 'epoch': 0.15}\n",
      "{'loss': 2.7658, 'grad_norm': 1.2084981203079224, 'learning_rate': 0.0001763612217795485, 'epoch': 0.16}\n",
      "{'loss': 2.7012, 'grad_norm': 1.3970896005630493, 'learning_rate': 0.00017370517928286854, 'epoch': 0.18}\n",
      "{'loss': 2.8436, 'grad_norm': 1.4035145044326782, 'learning_rate': 0.0001710491367861886, 'epoch': 0.19}\n",
      " 19%|███████▊                                 | 150/793 [01:04<04:26,  2.41it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.45it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.6565375328063965, 'eval_accuracy': 0.4716535433070866, 'eval_runtime': 0.4594, 'eval_samples_per_second': 21.769, 'eval_steps_per_second': 8.708, 'epoch': 0.19}\n",
      " 19%|███████▊                                 | 150/793 [01:04<04:26,  2.41it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.89it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.779, 'grad_norm': 1.231292724609375, 'learning_rate': 0.00016839309428950865, 'epoch': 0.2}\n",
      "{'loss': 2.9017, 'grad_norm': 1.457160234451294, 'learning_rate': 0.0001657370517928287, 'epoch': 0.21}\n",
      "{'loss': 2.8053, 'grad_norm': 1.3420770168304443, 'learning_rate': 0.00016308100929614876, 'epoch': 0.23}\n",
      "{'loss': 2.9426, 'grad_norm': 1.3133599758148193, 'learning_rate': 0.0001604249667994688, 'epoch': 0.24}\n",
      "{'loss': 2.8358, 'grad_norm': 1.2237982749938965, 'learning_rate': 0.00015776892430278885, 'epoch': 0.25}\n",
      " 25%|██████████▎                              | 200/793 [01:25<04:06,  2.41it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.663896322250366, 'eval_accuracy': 0.4716535433070866, 'eval_runtime': 0.463, 'eval_samples_per_second': 21.599, 'eval_steps_per_second': 8.64, 'epoch': 0.25}\n",
      " 25%|██████████▎                              | 200/793 [01:25<04:06,  2.41it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.77it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.6381, 'grad_norm': 1.4750229120254517, 'learning_rate': 0.0001551128818061089, 'epoch': 0.26}\n",
      "{'loss': 2.6884, 'grad_norm': 1.2598780393600464, 'learning_rate': 0.00015245683930942896, 'epoch': 0.28}\n",
      "{'loss': 2.7854, 'grad_norm': 1.8011668920516968, 'learning_rate': 0.000149800796812749, 'epoch': 0.29}\n",
      "{'loss': 2.9117, 'grad_norm': 1.2609130144119263, 'learning_rate': 0.00014714475431606907, 'epoch': 0.3}\n",
      "{'loss': 2.8475, 'grad_norm': 1.3099714517593384, 'learning_rate': 0.00014448871181938912, 'epoch': 0.32}\n",
      " 32%|████████████▉                            | 250/793 [01:46<03:45,  2.40it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.655327320098877, 'eval_accuracy': 0.4748031496062992, 'eval_runtime': 0.4597, 'eval_samples_per_second': 21.753, 'eval_steps_per_second': 8.701, 'epoch': 0.32}\n",
      " 32%|████████████▉                            | 250/793 [01:46<03:45,  2.40it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.90it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.8161, 'grad_norm': 1.4454635381698608, 'learning_rate': 0.00014183266932270918, 'epoch': 0.33}\n",
      "{'loss': 2.8191, 'grad_norm': 1.4206103086471558, 'learning_rate': 0.00013917662682602923, 'epoch': 0.34}\n",
      "{'loss': 2.857, 'grad_norm': 1.8560209274291992, 'learning_rate': 0.00013652058432934926, 'epoch': 0.35}\n",
      "{'loss': 2.8269, 'grad_norm': 1.2626043558120728, 'learning_rate': 0.0001338645418326693, 'epoch': 0.37}\n",
      "{'loss': 2.7757, 'grad_norm': 1.3425157070159912, 'learning_rate': 0.00013120849933598937, 'epoch': 0.38}\n",
      " 38%|███████████████▌                         | 300/793 [02:07<03:25,  2.39it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.6222853660583496, 'eval_accuracy': 0.48031496062992124, 'eval_runtime': 0.4692, 'eval_samples_per_second': 21.313, 'eval_steps_per_second': 8.525, 'epoch': 0.38}\n",
      " 38%|███████████████▌                         | 300/793 [02:08<03:25,  2.39it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.54it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.726, 'grad_norm': 1.2686539888381958, 'learning_rate': 0.00012855245683930942, 'epoch': 0.39}\n",
      "{'loss': 2.8378, 'grad_norm': 1.141784429550171, 'learning_rate': 0.00012589641434262948, 'epoch': 0.4}\n",
      "{'loss': 2.6942, 'grad_norm': 1.6625137329101562, 'learning_rate': 0.00012324037184594953, 'epoch': 0.42}\n",
      "{'loss': 2.779, 'grad_norm': 1.1944220066070557, 'learning_rate': 0.0001205843293492696, 'epoch': 0.43}\n",
      "{'loss': 2.7958, 'grad_norm': 1.3653637170791626, 'learning_rate': 0.00011792828685258966, 'epoch': 0.44}\n",
      " 44%|██████████████████                       | 350/793 [02:29<03:04,  2.40it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.6177639961242676, 'eval_accuracy': 0.48031496062992124, 'eval_runtime': 0.4597, 'eval_samples_per_second': 21.751, 'eval_steps_per_second': 8.701, 'epoch': 0.44}\n",
      " 44%|██████████████████                       | 350/793 [02:29<03:04,  2.40it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.90it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.8959, 'grad_norm': 1.2885241508483887, 'learning_rate': 0.00011527224435590971, 'epoch': 0.45}\n",
      "{'loss': 2.8173, 'grad_norm': 1.3564046621322632, 'learning_rate': 0.00011261620185922976, 'epoch': 0.47}\n",
      "{'loss': 2.7187, 'grad_norm': 1.2487002611160278, 'learning_rate': 0.00010996015936254979, 'epoch': 0.48}\n",
      "{'loss': 2.655, 'grad_norm': 1.2931064367294312, 'learning_rate': 0.00010730411686586985, 'epoch': 0.49}\n",
      "{'loss': 2.7284, 'grad_norm': 1.1671574115753174, 'learning_rate': 0.0001046480743691899, 'epoch': 0.5}\n",
      " 50%|████████████████████▋                    | 400/793 [02:50<02:43,  2.40it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.33it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.6136107444763184, 'eval_accuracy': 0.4811023622047244, 'eval_runtime': 0.4634, 'eval_samples_per_second': 21.577, 'eval_steps_per_second': 8.631, 'epoch': 0.5}\n",
      " 50%|████████████████████▋                    | 400/793 [02:50<02:43,  2.40it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.76it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.6629, 'grad_norm': 1.3458302021026611, 'learning_rate': 0.00010199203187250996, 'epoch': 0.52}\n",
      "{'loss': 2.8816, 'grad_norm': 1.4382002353668213, 'learning_rate': 9.933598937583003e-05, 'epoch': 0.53}\n",
      "{'loss': 2.6331, 'grad_norm': 1.4361592531204224, 'learning_rate': 9.667994687915008e-05, 'epoch': 0.54}\n",
      "{'loss': 2.7269, 'grad_norm': 1.557731032371521, 'learning_rate': 9.402390438247013e-05, 'epoch': 0.55}\n",
      "{'loss': 2.716, 'grad_norm': 1.3942360877990723, 'learning_rate': 9.136786188579018e-05, 'epoch': 0.57}\n",
      " 57%|███████████████████████▎                 | 450/793 [03:11<02:22,  2.40it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.25it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.5733823776245117, 'eval_accuracy': 0.4795275590551181, 'eval_runtime': 0.4638, 'eval_samples_per_second': 21.561, 'eval_steps_per_second': 8.625, 'epoch': 0.57}\n",
      " 57%|███████████████████████▎                 | 450/793 [03:12<02:22,  2.40it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.75it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.8245, 'grad_norm': 1.385614275932312, 'learning_rate': 8.871181938911023e-05, 'epoch': 0.58}\n",
      "{'loss': 2.7941, 'grad_norm': 1.6681671142578125, 'learning_rate': 8.605577689243029e-05, 'epoch': 0.59}\n",
      "{'loss': 2.8114, 'grad_norm': 2.0391578674316406, 'learning_rate': 8.339973439575034e-05, 'epoch': 0.61}\n",
      "{'loss': 2.7394, 'grad_norm': 1.344404935836792, 'learning_rate': 8.074369189907038e-05, 'epoch': 0.62}\n",
      "{'loss': 2.7247, 'grad_norm': 1.2690061330795288, 'learning_rate': 7.808764940239044e-05, 'epoch': 0.63}\n",
      " 63%|█████████████████████████▊               | 500/793 [03:33<02:02,  2.40it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.33it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.5638084411621094, 'eval_accuracy': 0.4858267716535433, 'eval_runtime': 0.4689, 'eval_samples_per_second': 21.326, 'eval_steps_per_second': 8.53, 'epoch': 0.63}\n",
      " 63%|█████████████████████████▊               | 500/793 [03:33<02:02,  2.40it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.54it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.8721, 'grad_norm': 1.2808220386505127, 'learning_rate': 7.543160690571049e-05, 'epoch': 0.64}\n",
      "{'loss': 2.6975, 'grad_norm': 1.5881104469299316, 'learning_rate': 7.277556440903055e-05, 'epoch': 0.66}\n",
      "{'loss': 2.7645, 'grad_norm': 1.4496285915374756, 'learning_rate': 7.01195219123506e-05, 'epoch': 0.67}\n",
      "{'loss': 2.784, 'grad_norm': 1.3601034879684448, 'learning_rate': 6.746347941567066e-05, 'epoch': 0.68}\n",
      "{'loss': 2.7112, 'grad_norm': 1.2615692615509033, 'learning_rate': 6.480743691899071e-05, 'epoch': 0.69}\n",
      " 69%|████████████████████████████▍            | 550/793 [03:55<01:41,  2.40it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.36it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.5442163944244385, 'eval_accuracy': 0.48661417322834644, 'eval_runtime': 0.4612, 'eval_samples_per_second': 21.68, 'eval_steps_per_second': 8.672, 'epoch': 0.69}\n",
      " 69%|████████████████████████████▍            | 550/793 [03:55<01:41,  2.40it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.86it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.6116, 'grad_norm': 1.562350869178772, 'learning_rate': 6.215139442231077e-05, 'epoch': 0.71}\n",
      "{'loss': 2.7142, 'grad_norm': 1.356479287147522, 'learning_rate': 5.9495351925630814e-05, 'epoch': 0.72}\n",
      "{'loss': 2.7024, 'grad_norm': 1.3376845121383667, 'learning_rate': 5.683930942895087e-05, 'epoch': 0.73}\n",
      "{'loss': 2.6857, 'grad_norm': 1.2647271156311035, 'learning_rate': 5.418326693227092e-05, 'epoch': 0.74}\n",
      "{'loss': 2.7197, 'grad_norm': 1.2148417234420776, 'learning_rate': 5.152722443559097e-05, 'epoch': 0.76}\n",
      " 76%|███████████████████████████████          | 600/793 [04:16<01:20,  2.40it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.540189266204834, 'eval_accuracy': 0.4889763779527559, 'eval_runtime': 0.4622, 'eval_samples_per_second': 21.634, 'eval_steps_per_second': 8.654, 'epoch': 0.76}\n",
      " 76%|███████████████████████████████          | 600/793 [04:16<01:20,  2.40it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.82it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.7142, 'grad_norm': 1.3424737453460693, 'learning_rate': 4.8871181938911026e-05, 'epoch': 0.77}\n",
      "{'loss': 2.6048, 'grad_norm': 1.5600075721740723, 'learning_rate': 4.6215139442231074e-05, 'epoch': 0.78}\n",
      "{'loss': 2.8204, 'grad_norm': 1.346793293952942, 'learning_rate': 4.355909694555113e-05, 'epoch': 0.79}\n",
      "{'loss': 2.7563, 'grad_norm': 1.4535577297210693, 'learning_rate': 4.0903054448871184e-05, 'epoch': 0.81}\n",
      "{'loss': 2.6007, 'grad_norm': 1.2657365798950195, 'learning_rate': 3.824701195219124e-05, 'epoch': 0.82}\n",
      " 82%|█████████████████████████████████▌       | 650/793 [04:37<00:59,  2.40it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.34it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.5220019817352295, 'eval_accuracy': 0.4881889763779528, 'eval_runtime': 0.4619, 'eval_samples_per_second': 21.648, 'eval_steps_per_second': 8.659, 'epoch': 0.82}\n",
      " 82%|█████████████████████████████████▌       | 650/793 [04:38<00:59,  2.40it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.83it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.7642, 'grad_norm': 1.2993484735488892, 'learning_rate': 3.5590969455511294e-05, 'epoch': 0.83}\n",
      "{'loss': 2.787, 'grad_norm': 1.3028721809387207, 'learning_rate': 3.293492695883134e-05, 'epoch': 0.84}\n",
      "{'loss': 2.7817, 'grad_norm': 1.4592231512069702, 'learning_rate': 3.0278884462151397e-05, 'epoch': 0.86}\n",
      "{'loss': 2.657, 'grad_norm': 1.341450572013855, 'learning_rate': 2.7622841965471448e-05, 'epoch': 0.87}\n",
      "{'loss': 2.7008, 'grad_norm': 1.3648351430892944, 'learning_rate': 2.4966799468791503e-05, 'epoch': 0.88}\n",
      " 88%|████████████████████████████████████▏    | 700/793 [04:59<00:38,  2.40it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.26it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.516385555267334, 'eval_accuracy': 0.48976377952755906, 'eval_runtime': 0.4644, 'eval_samples_per_second': 21.534, 'eval_steps_per_second': 8.613, 'epoch': 0.88}\n",
      " 88%|████████████████████████████████████▏    | 700/793 [04:59<00:38,  2.40it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.75it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.7098, 'grad_norm': 1.429010272026062, 'learning_rate': 2.2310756972111554e-05, 'epoch': 0.9}\n",
      "{'loss': 2.6757, 'grad_norm': 1.3088366985321045, 'learning_rate': 1.9654714475431606e-05, 'epoch': 0.91}\n",
      "{'loss': 2.7627, 'grad_norm': 1.3924505710601807, 'learning_rate': 1.699867197875166e-05, 'epoch': 0.92}\n",
      "{'loss': 2.6747, 'grad_norm': 1.6786681413650513, 'learning_rate': 1.4342629482071715e-05, 'epoch': 0.93}\n",
      "{'loss': 2.6894, 'grad_norm': 1.4466722011566162, 'learning_rate': 1.1686586985391767e-05, 'epoch': 0.95}\n",
      " 95%|██████████████████████████████████████▊  | 750/793 [05:20<00:17,  2.39it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:00<00:00, 16.32it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.509937286376953, 'eval_accuracy': 0.4937007874015748, 'eval_runtime': 0.4632, 'eval_samples_per_second': 21.588, 'eval_steps_per_second': 8.635, 'epoch': 0.95}\n",
      " 95%|██████████████████████████████████████▊  | 750/793 [05:20<00:17,  2.39it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 11.78it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.6815, 'grad_norm': 1.361688256263733, 'learning_rate': 9.03054448871182e-06, 'epoch': 0.96}\n",
      "{'loss': 2.6361, 'grad_norm': 1.2852981090545654, 'learning_rate': 6.374501992031872e-06, 'epoch': 0.97}\n",
      "{'loss': 2.6428, 'grad_norm': 1.1402758359909058, 'learning_rate': 3.718459495351926e-06, 'epoch': 0.98}\n",
      "{'loss': 2.6953, 'grad_norm': 1.1745314598083496, 'learning_rate': 1.0624169986719788e-06, 'epoch': 1.0}\n",
      "{'train_runtime': 338.7602, 'train_samples_per_second': 7.02, 'train_steps_per_second': 2.341, 'train_loss': 2.7944508380577213, 'epoch': 1.0}\n",
      "100%|█████████████████████████████████████████| 793/793 [05:38<00:00,  2.34it/s]\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     2.7945\n",
      "  train_runtime            = 0:05:38.76\n",
      "  train_samples            =       2378\n",
      "  train_samples_per_second =       7.02\n",
      "  train_steps_per_second   =      2.341\n",
      "\u001b[32m2024-03-14 11:08:34.068\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m754\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 338.7602, 'train_samples_per_second': 7.02, 'train_steps_per_second': 2.341, 'train_loss': 2.7944508380577213, 'epoch': 1.0, 'train_samples': 2378}\u001b[0m\n",
      "\u001b[32m2024-03-14 11:08:34.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m755\u001b[0m - \u001b[1mSaving model checkpoint to outputs-pt-v1\u001b[0m\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-03-14 11:08:34.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m763\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 12.11it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_accuracy           =     0.4929\n",
      "  eval_loss               =     2.5085\n",
      "  eval_runtime            = 0:00:00.46\n",
      "  eval_samples            =         10\n",
      "  eval_samples_per_second =     21.397\n",
      "  eval_steps_per_second   =      8.559\n",
      "  perplexity              =    12.2861\n",
      "\u001b[32m2024-03-14 11:08:34.719\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m776\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 2.5084705352783203, 'eval_accuracy': 0.49291338582677163, 'eval_runtime': 0.4673, 'eval_samples_per_second': 21.397, 'eval_steps_per_second': 8.559, 'epoch': 1.0, 'eval_samples': 10, 'perplexity': 12.286124488975172}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python pretraining.py \\\n",
    "    --model_type baichuan \\\n",
    "    --model_name_or_path /data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat \\\n",
    "    --train_file_dir ./data/pretrain \\\n",
    "    --validation_file_dir ./data/pretrain \\\n",
    "    --per_device_train_batch_size 3 \\\n",
    "    --per_device_eval_batch_size 3 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --use_peft True \\\n",
    "    --seed 42 \\\n",
    "    --fp16 \\\n",
    "    --max_train_samples 20000 \\\n",
    "    --max_eval_samples 10 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --learning_rate 2e-4 \\\n",
    "    --warmup_ratio 0.05 \\\n",
    "    --weight_decay 0.01 \\\n",
    "    --logging_strategy steps \\\n",
    "    --logging_steps 10 \\\n",
    "    --eval_steps 50 \\\n",
    "    --evaluation_strategy steps \\\n",
    "    --save_steps 500 \\\n",
    "    --save_strategy steps \\\n",
    "    --save_total_limit 3 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --preprocessing_num_workers 1 \\\n",
    "    --block_size 128 \\\n",
    "    --group_by_length True \\\n",
    "    --output_dir outputs-pt-v1 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --ddp_timeout 30000 \\\n",
    "    --logging_first_step True \\\n",
    "    --target_modules all \\\n",
    "    --lora_rank 8 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --torch_dtype float16 \\\n",
    "    --device_map auto \\\n",
    "    --report_to tensorboard \\\n",
    "    --ddp_find_unused_parameters False \\\n",
    "    --gradient_checkpointing True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 71M\n",
      "-rw-r--r-- 1 root root  714 Mar 14 11:08 adapter_config.json\n",
      "-rw-r--r-- 1 root root  69M Mar 14 11:08 adapter_model.safetensors\n",
      "-rw-r--r-- 1 root root  435 Mar 14 11:08 all_results.json\n",
      "drwxr-xr-x 2 root root  195 Mar 14 11:06 \u001b[0m\u001b[01;34mcheckpoint-500\u001b[0m/\n",
      "-rw-r--r-- 1 root root  264 Mar 14 11:08 eval_results.json\n",
      "-rw-r--r-- 1 root root 5.1K Mar 14 11:08 README.md\n",
      "drwxr-xr-x 3 root root   58 Mar 14 11:02 \u001b[01;34mruns\u001b[0m/\n",
      "-rw-r--r-- 1 root root  548 Mar 14 11:08 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root 9.8K Mar 14 11:08 tokenization_baichuan.py\n",
      "-rw-r--r-- 1 root root  968 Mar 14 11:08 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 2.0M Mar 14 11:08 tokenizer.model\n",
      "-rw-r--r-- 1 root root  17K Mar 14 11:08 trainer_state.json\n",
      "-rw-r--r-- 1 root root  191 Mar 14 11:08 train_results.json\n"
     ]
    }
   ],
   "source": [
    "%ls -lh outputs-pt-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练结果：\n",
    "- 使用lora训练模型，则保存的lora权重是`adapter_model.bin`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
    "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_type='baichuan', base_model='/data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat', tokenizer_path=None, lora_model='outputs-pt-v1', resize_emb=False, output_dir='merged-pt/')\n",
      "Base model: /data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat\n",
      "LoRA model: outputs-pt-v1\n",
      "Loading LoRA for causal language model\n",
      "Merging with merge_and_unload...\n",
      "Saving to Hugging Face format...\n",
      "Done! model saved to merged-pt/\n"
     ]
    }
   ],
   "source": [
    "!python merge_peft_adapter.py --model_type baichuan \\\n",
    "    --base_model /data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat --lora_model outputs-pt-v1 --output_dir merged-pt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14G\n",
      "-rw-r--r-- 1 root root  869 Mar 14 11:44 config.json\n",
      "-rw-r--r-- 1 root root 2.4K Mar 14 11:44 configuration_baichuan.py\n",
      "-rw-r--r-- 1 root root  285 Mar 14 11:44 generation_config.json\n",
      "-rw-r--r-- 1 root root 2.9K Mar 14 11:44 generation_utils.py\n",
      "-rw-r--r-- 1 root root  33K Mar 14 11:44 modeling_baichuan.py\n",
      "-rw-r--r-- 1 root root 4.7G Mar 14 11:44 pytorch_model-00001-of-00004.bin\n",
      "-rw-r--r-- 1 root root 4.7G Mar 14 11:44 pytorch_model-00002-of-00004.bin\n",
      "-rw-r--r-- 1 root root 3.8G Mar 14 11:45 pytorch_model-00003-of-00004.bin\n",
      "-rw-r--r-- 1 root root 983M Mar 14 11:45 pytorch_model-00004-of-00004.bin\n",
      "-rw-r--r-- 1 root root  19K Mar 14 11:45 pytorch_model.bin.index.json\n",
      "-rw-r--r-- 1 root root 8.9K Mar 14 11:44 quantizer.py\n",
      "-rw-r--r-- 1 root root  548 Mar 14 11:44 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root 9.8K Mar 14 11:44 tokenization_baichuan.py\n",
      "-rw-r--r-- 1 root root  942 Mar 14 11:44 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 2.0M Mar 14 11:44 tokenizer.model\n"
     ]
    }
   ],
   "source": [
    "%ls -lh merged-pt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_from_model_config\": true,\n",
      "  \"_name_or_path\": \"/data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat\",\n",
      "  \"architectures\": [\n",
      "    \"BaichuanForCausalLM\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_baichuan.BaichuanConfig\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_baichuan.BaichuanForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"baichuan\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"BaichuanTokenizer\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.38.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 125696,\n",
      "  \"z_loss_weight\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%cat merged-pt/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage1 增量预训练完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T13:56:17.081153Z",
     "start_time": "2023-06-15T13:56:17.032821Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Stage 2: Supervised FineTuning\n",
    "\n",
    "第二阶段：SFT(Supervised Fine-tuning)有监督微调，构造指令微调数据集，在预训练模型基础上做指令精调，以对齐指令意图，并注入领域知识\n",
    "\n",
    "| Stage 2: Supervised Fine-tuning | [supervised_finetuning.py](https://github.com/shibing624/MedicalGPT/blob/main/supervised_finetuning.py) | [run_sft.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_sft.sh)  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 说明：\n",
    "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
    "\n",
    "1. 生成模型：使用的是Bloom的`bigscience/bloomz-560m` 或者 Stage1得到的预训练模型\n",
    "2. 数据集：SFT阶段使用的是使用的是Belle的1千条抽样数据，位于`data/finetune`文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Stage2 咱们开始吧\n",
    "\n",
    "训练步骤如下：\n",
    "\n",
    "1. 确认训练集\n",
    "2. 执行训练脚本\n",
    "\n",
    "训练脚本的执行逻辑如下：\n",
    "1. 导入依赖包\n",
    "2. 设置参数\n",
    "3. 定义各函数并加载训练集\n",
    "4. 加载模型和tokenizer\n",
    "5. 开始训练并评估\n",
    "6. 查看训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T13:58:38.966506Z",
     "start_time": "2023-06-15T13:58:38.778132Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical_sft_1K_format.jsonl  sharegpt_zh_1K_format.jsonl\n"
     ]
    }
   ],
   "source": [
    "%ls ./data/finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-14 16:04:22.890\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m222\u001b[0m - \u001b[33m\u001b[1mYou may set max_train_samples = -1 to run all samples in production.\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:22.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m983\u001b[0m - \u001b[1mModel args: ModelArguments(model_type='baichuan', model_name_or_path='/data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat', load_in_8bit=False, load_in_4bit=False, tokenizer_name_or_path=None, cache_dir=None, model_revision='main', hf_hub_token=None, use_fast_tokenizer=False, torch_dtype='float16', device_map='auto', trust_remote_code=True, rope_scaling=None, flash_attn=False, shift_attn=False, neft_alpha=0)\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:22.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m984\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/finetune', validation_file_dir='./data/finetune', template_name='vicuna', max_train_samples=1000, max_eval_samples=10, ignore_pad_token_for_loss=True, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=1)\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:22.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m985\u001b[0m - \u001b[1mTraining args: Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=False,\n",
      "ddp_timeout=30000,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=steps,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=outputs-sft-v1/runs/Mar14_16-04-22_sg-gpt-01.tc-bj7.songguo7.com,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=outputs-sft-v1,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=outputs-sft-v1,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.05,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.05,\n",
      ")\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:22.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m986\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, train_on_inputs=False, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, qlora=False, model_max_length=512)\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:22.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m987\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:23.206\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1017\u001b[0m - \u001b[34m\u001b[1mTokenizer: BaichuanTokenizer(name_or_path='/data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat', vocab_size=125696, model_max_length=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "}\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:23.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1044\u001b[0m - \u001b[1mtrain files: ['./data/finetune/medical_sft_1K_format.jsonl', './data/finetune/sharegpt_zh_1K_format.jsonl']\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:23.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1049\u001b[0m - \u001b[1meval files: ['./data/finetune/medical_sft_1K_format.jsonl', './data/finetune/sharegpt_zh_1K_format.jsonl']\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:24.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1065\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['conversations'],\n",
      "        num_rows: 2006\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['conversations'],\n",
      "        num_rows: 2006\n",
      "    })\n",
      "})\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:24.667\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1156\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'conversations': [{'from': 'human', 'value': '用简单的语言解释量子计算。'}, {'from': 'gpt', 'value': '量子计算是一种使用量子比特或量子位(qubits)而不是经典比特的计算。量子位可以同时存在于多个状态中，这使它们能够同时执行许多计算。\\n\\n在经典计算中，比特只能处于0或1的两种状态之一。然而，在量子计算中，量子位可以同时处于多个状态，这被称为叠加态。这意味着单个量子位可以同时表示许多不同的值。\\n\\n此外，量子位还可以被纠缠，这意味着一个量子位的状态可以影响另一个量子位的状态，即使它们相隔数千公里。这种纠缠的属性使得量子计算机比经典计算机更快地执行某些计算。\\n\\n总的来说，量子计算具有革命性的潜力，可以通过更快速和更高效地计算复杂问题来改变许多领域，包括加密、化学和人工智能。'}]}\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:24.701\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1167\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 999\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:24.702\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1168\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:24.709\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1169\u001b[0m - \u001b[34m\u001b[1mDecode input_ids[0]:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s> USER: 回答二年级家庭作业\n",
      "Hugo的《被判死刑犯的最后一天》Larousse版\n",
      "\n",
      "除了第4，7和16题以外，所有问题都是1分。\n",
      "回答以下问题时，请务必注意您的答案的撰写。\n",
      "\n",
      "1 / 审判是哪个月？故事发生在什么时间？有哪些地点？能确切地知道日期吗？请解释您的答案。/ 2\n",
      "2/ 宣布判决死刑时，群众的态度如何？为什么您认为会有这样的反应？/ 1\n",
      "3/“索邦大学和鬼脸”这个词汇用于描述一个小偷，属于哪种语言风格？请解释。/ 1\n",
      "4/ 促使被判死刑的三个原因是什么？/ 2\n",
      "5/ 他不愿意写的原因是什么？/ 1\n",
      "6/ 显示被判死刑者对他的日记的用处持怀疑态度。/ 1\n",
      "7/ 描述被判死刑者的家庭并说明他是否重视家庭。/ 2\n",
      "8/ 被判死刑者希望什么，为什么？/ 1\n",
      "9/ 在牢房里听一首歌曲会引起什么感受？为什么？/ 1\n",
      "10/ 解释神父弄掉香烟的那一段？为什么这个情况是反话的呢？/ 1\n",
      "11 / 什么是“friauche”？为什么被判死刑的人会上当受骗？/ 1\n",
      "12/ 如何区分被判死刑者的护照？/ 1\n",
      "13/ 警官向囚犯提供了一项完全荒谬的建议是什么？/ 1\n",
      "14/ 什么童年回忆最深刻？为什么恰恰是这个？/ 1\n",
      "15/ 为什么被判死刑的人对玛丽的访问感到失望？/ 1\n",
      "16/ 简要说明Victor Hugo如何叙述被判死刑者的处决过程。为什么通过这种方式叙述更加引人注目？/ 2 ASSISTANT:</s>\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:24.716\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1172\u001b[0m - \u001b[34m\u001b[1mDecode labels[0]: <unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk></s>\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:24.718\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1186\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:24.718\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1190\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'conversations': [{'from': 'human', 'value': '治疗阳痿吃什么药呢？，性生活一直很正常的，但是这段时间感觉性欲变低了，有时勃起都感觉很困难，试过许多的方法都没效果，听朋友说我这种情况可能会是早泄，想知道治疗早泄的药物？'}, {'from': 'gpt', 'value': '男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。'}]}\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:24.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1200\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:24.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1201\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:24.753\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1202\u001b[0m - \u001b[34m\u001b[1m A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s> USER: 治疗阳痿吃什么药呢？，性生活一直很正常的，但是这段时间感觉性欲变低了，有时勃起都感觉很困难，试过许多的方法都没效果，听朋友说我这种情况可能会是早泄，想知道治疗早泄的药物？ ASSISTANT:男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。</s>\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:32.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1336\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:32.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1351\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:32.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1360\u001b[0m - \u001b[1mPeft target_modules: ['W_pack', 'down_proj', 'gate_proj', 'o_proj', 'up_proj']\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:32.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1361\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
      "trainable params: 17,891,328 || all params: 7,523,864,576 || trainable%: 0.23779439168895536\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "\u001b[32m2024-03-14 16:04:33.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1383\u001b[0m - \u001b[1mGradient checkpointing enabled.\u001b[0m\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[32m2024-03-14 16:04:33.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1411\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:33.124\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1414\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids': tensor([[92343, 15161,  2357,  ...,     0,     0,     0],\n",
      "        [92343, 15161,  2357,  ...,  1874,    67,     2],\n",
      "        [92343, 15161,  2357,  ...,     0,     0,     0],\n",
      "        [92343, 15161,  2357,  ...,     0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., 1874,   67,    2],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]], device='cuda:0')}\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:33.151\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1415\u001b[0m - \u001b[34m\u001b[1mDetail input_ids: [tensor([92343, 15161,  2357,  1346, 23815,  5322,  1377,  1452, 19649, 11656,\n",
      "        14002,    72,  1481, 14002,  6474, 13629, 92323, 11144, 92323,  1377,\n",
      "        70217, 13514,  1375,  1352,  5322, 92404, 92319,  4852,    72,     2,\n",
      "        62426, 92345, 92311, 93154, 93794, 93848, 92333,  9172, 15122, 18016,\n",
      "        78816,    68, 62163, 15202, 21250, 92345,  8512,     2,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0], device='cuda:0'), tensor([ 92343,  15161,   2357,   1346,  23815,   5322,   1377,   1452,  19649,\n",
      "         11656,  14002,     72,   1481,  14002,   6474,  13629,  92323,  11144,\n",
      "         92323,   1377,  70217,  13514,   1375,   1352,   5322,  92404,  92319,\n",
      "          4852,     72,      2,  62426,  92345,  92311,  53844,   2683,  14198,\n",
      "          2769,  93851,     65,  70463,  92323,   2016,  17020,  92366,     72,\n",
      "         92672,  94064,  96201,  92323,   9580,  93345,  93208,  92890,  93376,\n",
      "         92349,  93151,  92323,   4924,   6437,     72,  92825,  93451,  92428,\n",
      "         92323,  83639,  92428,  92323,  11563,  93635,  94171,     72,   2016,\n",
      "         21873,  94096,  31147,  11014,  92323,  31147,  94368,  94368,  92333,\n",
      "         92323,   6239,  94145,  92323,   6180,  92355,  92354,  92383,     72,\n",
      "         92338,  92919,  93862,     72,  93345,  93208,  92890,  92347,  93403,\n",
      "         92706,  92369,  92335,  92543,  92919,  93862,  92323,  30704,  92982,\n",
      "         92336,  92354,  92335,  92543,  92919,  93862,     72,  93360,  92380,\n",
      "         93403,  92706,  92543,  92919,  93862,     72,   6251,  94975,  92323,\n",
      "          4924,  93345,  93208,  92890,  92428,  93003,  92650,  62345,  92358,\n",
      "         92338,  62706,  66124,   2683,     72,  23168,   9688,  29248,   2887,\n",
      "            70,   7237,  92383,  19635,  92576,  92382,  13621,   2157,  37615,\n",
      "         92488,  92540,  57245,  92323,  92623,  92357,  41712,  95998,  93045,\n",
      "         93987,  92323,   3722,  40586,   5473,  92347,  70463,  92323,  92457,\n",
      "          1713,  92366,  92590,  92405,   5473,   6159,     72,  19543,  14070,\n",
      "          9036,     70,  28850,  92392,   1713,   2002,   2683,  93122,     74,\n",
      "         25989,   7020,   2769,     74,   6137,  62163,  15202,  21250,  92345,\n",
      "          2683,  27651,  92572,  92398,  92323,   4965,  35317,   9688,   2800,\n",
      "            89,  92411,   6678,  49834,  38721,  11921,     66,  92467,  94831,\n",
      "         92495,  92411,  92333,  93204,  92600,  59545,  93187,  94831,  92495,\n",
      "         92411,  92333,  93204,  92323,   5558,  92358, 100396,  92336,  92335,\n",
      "         10976,  92395,   8400,  92323,  93322,  93959,   1328,   1274,   1237,\n",
      "         92600,  92416,  93964,  92964,  93204,  92335,     66,  92336, 100396,\n",
      "         92335,     66,  92338,  92358,  10976,  58070,   8400,  99025,  92543,\n",
      "         97905,  92323,  93322,  93959,   1328,   1274,   1237,  92600,   6033,\n",
      "         93204,  92336, 100396,  92338,  10976,  58070,   8400,  99025,  92322,\n",
      "          1716,  92431,  92543,  24377,  92323,   2771,  35864,  92354, 100396,\n",
      "         92358,  92322,     66,   6678,  11921,  92380,  19299,  92838,   3386,\n",
      "         27455,  92457,   6557,     66,   2130,   8629,  92360,  28850,  92392,\n",
      "          1713,   2002,   2683,  92540,  33191,  92361,   1790,   7961,   2800,\n",
      "            65,  14900,  64297,  40797,     65,  45204,   1874,     67,      2],\n",
      "       device='cuda:0'), tensor([ 92343,  15161,   2357,   1346,  23815,   5322,   1377,   1452,  19649,\n",
      "         11656,  14002,     72,   1481,  14002,   6474,  13629,  92323,  11144,\n",
      "         92323,   1377,  70217,  13514,   1375,   1352,   5322,  92404,  92319,\n",
      "          4852,     72,      2,  62426,  92345, 100085,  12263,  92333,     65,\n",
      "         47659,  92333,   8143,   1367,  17568,   2218,   7660,  92344,  92347,\n",
      "          7168,   8143,   1367,  17568,  92333,  92336,  92335,  93714,   2835,\n",
      "            68,   8143,   1367,  17568,  92333,  67344,  92385,  12263,   2454,\n",
      "          5082,     68,  92676,  92993,  92649,  92372,  92550,   6843,   2602,\n",
      "          7879,   5987,   7522,     65,  92430,  93436,   2762,   5623,  93122,\n",
      "            68,  62163,  15202,  21250,  92345,  93349,  15417,  92667,     65,\n",
      "         76733,   6294,  94706,  95271,     65,  92347,  94706,  95271,  47513,\n",
      "         20237,     66,  12400,   7660,  92344,  11487,   4018,  25696,   3671,\n",
      "          1930,     65,  37046,   3543,   6294,   3639,  92364,  78654,  41637,\n",
      "         28129,  93490,  92385,  82543,     66,   4850,     65,   7660,  92344,\n",
      "         92415,  92787,     69,  92778,  92385,  28514,   9802,     65,  37046,\n",
      "         12263,  92385,  95828,  94072,  93349,  15417,  92667,  10874,     65,\n",
      "         92504,   7724,   5473,   9572,   4246,     66,      5,      5,  12263,\n",
      "         92385,  95828,  94072,   7262,   5473,   2101,  93349,  15417,  92667,\n",
      "         92364,  36723,  92333,   8460,     66,   2835,   8725,  39327,  12263,\n",
      "         92385,  95828,  94072,  93349,  15417,  92667,     70,      5,      5,\n",
      "         92336,     72,  92311,   6160,     70,  93349,  15417,  92667,  92545,\n",
      "          6714,   3327,   6902,  92380,  92569,  40760,   6160,     66,      5,\n",
      "         92338,     72,  92311,   9716,     70,  92545,   8742,  92516,   9716,\n",
      "            65,  19607,  37018,  92385,  48745,     66,      5,  92354,     72,\n",
      "         92311,  12263,     70,  92538,  92545,   6714,  44777,  12263,  28207,\n",
      "         22836,  12263,  93107,  92364,  12263,     65,  92391,  19607,  17831,\n",
      "         92594,   9535,  45134,     66,      5,  92369,     72,  92311,  95828,\n",
      "         94072,     70,  92538,  12263,  92333,  20237,  95828,  92419,  47659,\n",
      "            65,  41637,   4018,   6334,  92523,     66,      5,      5,  32974,\n",
      "            65,  92355,  12263,  92385,  95828,  94072,  93349,  15417,  92667,\n",
      "         10874,     65,  36723,   5473,  19599,     65,   5610,   7660,  92344,\n",
      "            66,   5060,     65,  12263,  92385,  95828,  94072,   2502,   7785,\n",
      "          5506,     65,  72976,  36723,  92333,   8460,   1890,  59333,   2381,\n",
      "            66,   2895,     65,  31155,  93349,  15417,  92667,  47659,   3269,\n",
      "            65,   5375,   2873,  92504,  35953,   1930,  25394,     66,      2,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0],\n",
      "       device='cuda:0')], \n",
      "labels: [tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 8512,    2,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
      "       device='cuda:0'), tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          2683,  27651,  92572,  92398,  92323,   4965,  35317,   9688,   2800,\n",
      "            89,  92411,   6678,  49834,  38721,  11921,     66,  92467,  94831,\n",
      "         92495,  92411,  92333,  93204,  92600,  59545,  93187,  94831,  92495,\n",
      "         92411,  92333,  93204,  92323,   5558,  92358, 100396,  92336,  92335,\n",
      "         10976,  92395,   8400,  92323,  93322,  93959,   1328,   1274,   1237,\n",
      "         92600,  92416,  93964,  92964,  93204,  92335,     66,  92336, 100396,\n",
      "         92335,     66,  92338,  92358,  10976,  58070,   8400,  99025,  92543,\n",
      "         97905,  92323,  93322,  93959,   1328,   1274,   1237,  92600,   6033,\n",
      "         93204,  92336, 100396,  92338,  10976,  58070,   8400,  99025,  92322,\n",
      "          1716,  92431,  92543,  24377,  92323,   2771,  35864,  92354, 100396,\n",
      "         92358,  92322,     66,   6678,  11921,  92380,  19299,  92838,   3386,\n",
      "         27455,  92457,   6557,     66,   2130,   8629,  92360,  28850,  92392,\n",
      "          1713,   2002,   2683,  92540,  33191,  92361,   1790,   7961,   2800,\n",
      "            65,  14900,  64297,  40797,     65,  45204,   1874,     67,      2],\n",
      "       device='cuda:0'), tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100, 93349, 15417, 92667,    65,\n",
      "        76733,  6294, 94706, 95271,    65, 92347, 94706, 95271, 47513, 20237,\n",
      "           66, 12400,  7660, 92344, 11487,  4018, 25696,  3671,  1930,    65,\n",
      "        37046,  3543,  6294,  3639, 92364, 78654, 41637, 28129, 93490, 92385,\n",
      "        82543,    66,  4850,    65,  7660, 92344, 92415, 92787,    69, 92778,\n",
      "        92385, 28514,  9802,    65, 37046, 12263, 92385, 95828, 94072, 93349,\n",
      "        15417, 92667, 10874,    65, 92504,  7724,  5473,  9572,  4246,    66,\n",
      "            5,     5, 12263, 92385, 95828, 94072,  7262,  5473,  2101, 93349,\n",
      "        15417, 92667, 92364, 36723, 92333,  8460,    66,  2835,  8725, 39327,\n",
      "        12263, 92385, 95828, 94072, 93349, 15417, 92667,    70,     5,     5,\n",
      "        92336,    72, 92311,  6160,    70, 93349, 15417, 92667, 92545,  6714,\n",
      "         3327,  6902, 92380, 92569, 40760,  6160,    66,     5, 92338,    72,\n",
      "        92311,  9716,    70, 92545,  8742, 92516,  9716,    65, 19607, 37018,\n",
      "        92385, 48745,    66,     5, 92354,    72, 92311, 12263,    70, 92538,\n",
      "        92545,  6714, 44777, 12263, 28207, 22836, 12263, 93107, 92364, 12263,\n",
      "           65, 92391, 19607, 17831, 92594,  9535, 45134,    66,     5, 92369,\n",
      "           72, 92311, 95828, 94072,    70, 92538, 12263, 92333, 20237, 95828,\n",
      "        92419, 47659,    65, 41637,  4018,  6334, 92523,    66,     5,     5,\n",
      "        32974,    65, 92355, 12263, 92385, 95828, 94072, 93349, 15417, 92667,\n",
      "        10874,    65, 36723,  5473, 19599,    65,  5610,  7660, 92344,    66,\n",
      "         5060,    65, 12263, 92385, 95828, 94072,  2502,  7785,  5506,    65,\n",
      "        72976, 36723, 92333,  8460,  1890, 59333,  2381,    66,  2895,    65,\n",
      "        31155, 93349, 15417, 92667, 47659,  3269,    65,  5375,  2873, 92504,\n",
      "        35953,  1930, 25394,    66,     2,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100], device='cuda:0')]\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:33.155\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1416\u001b[0m - \u001b[34m\u001b[1mDecode input_ids[0]:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s> USER: 汉诺塔的发病性别倾向是啥？ ASSISTANT:男性</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\u001b[0m\n",
      "\u001b[32m2024-03-14 16:04:33.181\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1419\u001b[0m - \u001b[34m\u001b[1mDecode labels[0]: <unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> 男性</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\u001b[0m\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "  0%|                                                  | 0/1250 [00:00<?, ?it/s]/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.2488, 'grad_norm': 1.4295227527618408, 'learning_rate': 3.174603174603175e-07, 'epoch': 0.0}\n",
      "{'loss': 2.5047, 'grad_norm': 2.2100017070770264, 'learning_rate': 3.1746031746031746e-06, 'epoch': 0.04}\n",
      "{'loss': 2.8487, 'grad_norm': 4.010144233703613, 'learning_rate': 6.349206349206349e-06, 'epoch': 0.08}\n",
      "{'loss': 2.4613, 'grad_norm': nan, 'learning_rate': 9.206349206349207e-06, 'epoch': 0.12}\n",
      "{'loss': 2.296, 'grad_norm': 1.4481425285339355, 'learning_rate': 1.2380952380952383e-05, 'epoch': 0.16}\n",
      "{'loss': 2.4868, 'grad_norm': 1.3643231391906738, 'learning_rate': 1.555555555555556e-05, 'epoch': 0.2}\n",
      "  4%|█▋                                       | 50/1250 [01:11<29:28,  1.47s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.8865368366241455, 'eval_runtime': 0.512, 'eval_samples_per_second': 19.53, 'eval_steps_per_second': 5.859, 'epoch': 0.2}\n",
      "  4%|█▋                                       | 50/1250 [01:11<29:28,  1.47s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.46it/s]\u001b[A\n",
      "{'loss': 2.7139, 'grad_norm': 1.8527048826217651, 'learning_rate': 1.8730158730158732e-05, 'epoch': 0.24}\n",
      "{'loss': 2.6026, 'grad_norm': 1.1482020616531372, 'learning_rate': 1.9898904802021906e-05, 'epoch': 0.28}\n",
      "{'loss': 2.2439, 'grad_norm': 1.283004641532898, 'learning_rate': 1.9730412805391747e-05, 'epoch': 0.32}\n",
      "{'loss': 2.2627, 'grad_norm': 0.9318049550056458, 'learning_rate': 1.9561920808761584e-05, 'epoch': 0.36}\n",
      "{'loss': 2.2951, 'grad_norm': 0.926104724407196, 'learning_rate': 1.9393428812131425e-05, 'epoch': 0.4}\n",
      "  8%|███▏                                    | 100/1250 [02:25<29:12,  1.52s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.3298239707946777, 'eval_runtime': 0.5067, 'eval_samples_per_second': 19.734, 'eval_steps_per_second': 5.92, 'epoch': 0.4}\n",
      "  8%|███▏                                    | 100/1250 [02:26<29:12,  1.52s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.33it/s]\u001b[A\n",
      "{'loss': 2.3812, 'grad_norm': 1.080867886543274, 'learning_rate': 1.9224936815501266e-05, 'epoch': 0.44}\n",
      "{'loss': 2.1586, 'grad_norm': 0.8494776487350464, 'learning_rate': 1.9056444818871104e-05, 'epoch': 0.48}\n",
      "{'loss': 2.0085, 'grad_norm': 1.1145919561386108, 'learning_rate': 1.8887952822240945e-05, 'epoch': 0.52}\n",
      "{'loss': 2.2726, 'grad_norm': 1.6835113763809204, 'learning_rate': 1.8719460825610786e-05, 'epoch': 0.56}\n",
      "{'loss': 2.2572, 'grad_norm': 1.2914735078811646, 'learning_rate': 1.8550968828980624e-05, 'epoch': 0.6}\n",
      " 12%|████▊                                   | 150/1250 [03:39<24:51,  1.36s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.248598098754883, 'eval_runtime': 0.5046, 'eval_samples_per_second': 19.818, 'eval_steps_per_second': 5.945, 'epoch': 0.6}\n",
      " 12%|████▊                                   | 150/1250 [03:40<24:51,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.37it/s]\u001b[A\n",
      "{'loss': 1.7789, 'grad_norm': 1.1858704090118408, 'learning_rate': 1.8382476832350465e-05, 'epoch': 0.64}\n",
      "{'loss': 2.4331, 'grad_norm': 0.9382167458534241, 'learning_rate': 1.8213984835720306e-05, 'epoch': 0.68}\n",
      "{'loss': 2.3577, 'grad_norm': 1.0823073387145996, 'learning_rate': 1.8045492839090143e-05, 'epoch': 0.72}\n",
      "{'loss': 2.1785, 'grad_norm': 1.2880806922912598, 'learning_rate': 1.7877000842459984e-05, 'epoch': 0.76}\n",
      "{'loss': 2.179, 'grad_norm': 0.7782329320907593, 'learning_rate': 1.7708508845829825e-05, 'epoch': 0.8}\n",
      " 16%|██████▍                                 | 200/1250 [04:55<28:56,  1.65s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.1625800132751465, 'eval_runtime': 0.5072, 'eval_samples_per_second': 19.717, 'eval_steps_per_second': 5.915, 'epoch': 0.8}\n",
      " 16%|██████▍                                 | 200/1250 [04:56<28:56,  1.65s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.34it/s]\u001b[A\n",
      "{'loss': 2.3336, 'grad_norm': 1.6493984460830688, 'learning_rate': 1.7540016849199663e-05, 'epoch': 0.84}\n",
      "{'loss': 2.2389, 'grad_norm': 0.844314694404602, 'learning_rate': 1.7371524852569504e-05, 'epoch': 0.88}\n",
      "{'loss': 2.0361, 'grad_norm': 1.2708983421325684, 'learning_rate': 1.7203032855939345e-05, 'epoch': 0.92}\n",
      "{'loss': 2.1685, 'grad_norm': 1.1693581342697144, 'learning_rate': 1.7034540859309182e-05, 'epoch': 0.96}\n",
      "{'loss': 2.2342, 'grad_norm': 1.18767511844635, 'learning_rate': 1.6866048862679024e-05, 'epoch': 1.0}\n",
      " 20%|████████                                | 250/1250 [06:07<19:13,  1.15s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.1321589946746826, 'eval_runtime': 0.5082, 'eval_samples_per_second': 19.678, 'eval_steps_per_second': 5.903, 'epoch': 1.0}\n",
      " 20%|████████                                | 250/1250 [06:08<19:13,  1.15s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.33it/s]\u001b[A\n",
      "{'loss': 1.8835, 'grad_norm': 1.4474812746047974, 'learning_rate': 1.6697556866048865e-05, 'epoch': 1.04}\n",
      "{'loss': 2.194, 'grad_norm': 2.103809356689453, 'learning_rate': 1.6529064869418706e-05, 'epoch': 1.08}\n",
      "{'loss': 2.0675, 'grad_norm': 0.9436125755310059, 'learning_rate': 1.6360572872788547e-05, 'epoch': 1.12}\n",
      "{'loss': 2.1413, 'grad_norm': 1.0581321716308594, 'learning_rate': 1.6192080876158384e-05, 'epoch': 1.16}\n",
      "{'loss': 1.9562, 'grad_norm': 1.8423413038253784, 'learning_rate': 1.6023588879528225e-05, 'epoch': 1.2}\n",
      " 24%|█████████▌                              | 300/1250 [07:21<23:05,  1.46s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.110590696334839, 'eval_runtime': 0.5095, 'eval_samples_per_second': 19.626, 'eval_steps_per_second': 5.888, 'epoch': 1.2}\n",
      " 24%|█████████▌                              | 300/1250 [07:21<23:05,  1.46s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.29it/s]\u001b[A\n",
      "{'loss': 2.3497, 'grad_norm': 2.252861738204956, 'learning_rate': 1.5855096882898063e-05, 'epoch': 1.24}\n",
      "{'loss': 1.9847, 'grad_norm': 0.7967568635940552, 'learning_rate': 1.5686604886267904e-05, 'epoch': 1.28}\n",
      "{'loss': 2.0317, 'grad_norm': 1.1567572355270386, 'learning_rate': 1.5518112889637745e-05, 'epoch': 1.32}\n",
      "{'loss': 1.9703, 'grad_norm': 1.2429546117782593, 'learning_rate': 1.5349620893007582e-05, 'epoch': 1.36}\n",
      "{'loss': 2.0003, 'grad_norm': 0.9282630681991577, 'learning_rate': 1.5181128896377423e-05, 'epoch': 1.4}\n",
      " 28%|███████████▏                            | 350/1250 [08:36<23:19,  1.56s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.051417589187622, 'eval_runtime': 0.5092, 'eval_samples_per_second': 19.639, 'eval_steps_per_second': 5.892, 'epoch': 1.4}\n",
      " 28%|███████████▏                            | 350/1250 [08:36<23:19,  1.56s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.31it/s]\u001b[A\n",
      "{'loss': 1.9208, 'grad_norm': 1.2047723531723022, 'learning_rate': 1.5012636899747265e-05, 'epoch': 1.44}\n",
      "{'loss': 2.2104, 'grad_norm': 1.797851800918579, 'learning_rate': 1.4844144903117104e-05, 'epoch': 1.48}\n",
      "{'loss': 2.2533, 'grad_norm': 1.2619755268096924, 'learning_rate': 1.4675652906486943e-05, 'epoch': 1.52}\n",
      "{'loss': 2.1632, 'grad_norm': 1.1355549097061157, 'learning_rate': 1.4507160909856784e-05, 'epoch': 1.56}\n",
      "{'loss': 2.2616, 'grad_norm': 4.676102161407471, 'learning_rate': 1.4338668913226623e-05, 'epoch': 1.6}\n",
      " 32%|████████████▊                           | 400/1250 [09:50<17:10,  1.21s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.053337335586548, 'eval_runtime': 0.5063, 'eval_samples_per_second': 19.75, 'eval_steps_per_second': 5.925, 'epoch': 1.6}\n",
      " 32%|████████████▊                           | 400/1250 [09:51<17:10,  1.21s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.36it/s]\u001b[A\n",
      "{'loss': 2.1803, 'grad_norm': 4.606509685516357, 'learning_rate': 1.4170176916596463e-05, 'epoch': 1.64}\n",
      "{'loss': 2.0073, 'grad_norm': 0.8742066621780396, 'learning_rate': 1.4001684919966302e-05, 'epoch': 1.68}\n",
      "{'loss': 2.031, 'grad_norm': 1.3402341604232788, 'learning_rate': 1.3833192923336143e-05, 'epoch': 1.72}\n",
      "{'loss': 2.1034, 'grad_norm': 1.922987461090088, 'learning_rate': 1.3664700926705982e-05, 'epoch': 1.76}\n",
      "{'loss': 1.8328, 'grad_norm': 0.9542073607444763, 'learning_rate': 1.3496208930075822e-05, 'epoch': 1.8}\n",
      " 36%|██████████████▍                         | 450/1250 [11:04<20:14,  1.52s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.0394527912139893, 'eval_runtime': 0.507, 'eval_samples_per_second': 19.725, 'eval_steps_per_second': 5.917, 'epoch': 1.8}\n",
      " 36%|██████████████▍                         | 450/1250 [11:04<20:14,  1.52s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.36it/s]\u001b[A\n",
      "{'loss': 2.1949, 'grad_norm': 1.3988432884216309, 'learning_rate': 1.3327716933445663e-05, 'epoch': 1.84}\n",
      "{'loss': 2.1021, 'grad_norm': 0.9902573823928833, 'learning_rate': 1.3159224936815502e-05, 'epoch': 1.88}\n",
      "{'loss': 2.1272, 'grad_norm': 1.6442639827728271, 'learning_rate': 1.2990732940185341e-05, 'epoch': 1.92}\n",
      "{'loss': 2.2231, 'grad_norm': 1.1716680526733398, 'learning_rate': 1.2822240943555182e-05, 'epoch': 1.96}\n",
      "{'loss': 2.0869, 'grad_norm': 1.232655644416809, 'learning_rate': 1.2653748946925022e-05, 'epoch': 2.0}\n",
      " 40%|████████████████                        | 500/1250 [12:21<19:05,  1.53s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.0498201847076416, 'eval_runtime': 0.5077, 'eval_samples_per_second': 19.697, 'eval_steps_per_second': 5.909, 'epoch': 2.0}\n",
      " 40%|████████████████                        | 500/1250 [12:22<19:05,  1.53s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.33it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 1.9124, 'grad_norm': 1.075728178024292, 'learning_rate': 1.2485256950294861e-05, 'epoch': 2.04}\n",
      "{'loss': 1.8333, 'grad_norm': 1.2262917757034302, 'learning_rate': 1.2316764953664702e-05, 'epoch': 2.08}\n",
      "{'loss': 1.9983, 'grad_norm': 1.7500922679901123, 'learning_rate': 1.2148272957034541e-05, 'epoch': 2.12}\n",
      "{'loss': 2.1317, 'grad_norm': 1.3739274740219116, 'learning_rate': 1.197978096040438e-05, 'epoch': 2.16}\n",
      "{'loss': 1.8131, 'grad_norm': 1.285178780555725, 'learning_rate': 1.1811288963774222e-05, 'epoch': 2.2}\n",
      " 44%|█████████████████▌                      | 550/1250 [13:37<18:24,  1.58s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.0105862617492676, 'eval_runtime': 0.5129, 'eval_samples_per_second': 19.498, 'eval_steps_per_second': 5.849, 'epoch': 2.2}\n",
      " 44%|█████████████████▌                      | 550/1250 [13:38<18:24,  1.58s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.26it/s]\u001b[A\n",
      "{'loss': 2.1696, 'grad_norm': 1.8869179487228394, 'learning_rate': 1.1642796967144061e-05, 'epoch': 2.24}\n",
      "{'loss': 1.848, 'grad_norm': 2.008951187133789, 'learning_rate': 1.14743049705139e-05, 'epoch': 2.28}\n",
      "{'loss': 2.0889, 'grad_norm': 1.0761216878890991, 'learning_rate': 1.1305812973883741e-05, 'epoch': 2.32}\n",
      "{'loss': 2.1788, 'grad_norm': 1.2272189855575562, 'learning_rate': 1.113732097725358e-05, 'epoch': 2.36}\n",
      "{'loss': 2.0456, 'grad_norm': 1.1605013608932495, 'learning_rate': 1.096882898062342e-05, 'epoch': 2.4}\n",
      " 48%|███████████████████▏                    | 600/1250 [14:54<16:13,  1.50s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.0243098735809326, 'eval_runtime': 0.5092, 'eval_samples_per_second': 19.639, 'eval_steps_per_second': 5.892, 'epoch': 2.4}\n",
      " 48%|███████████████████▏                    | 600/1250 [14:54<16:13,  1.50s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.32it/s]\u001b[A\n",
      "{'loss': 2.1835, 'grad_norm': 1.5804064273834229, 'learning_rate': 1.0800336983993261e-05, 'epoch': 2.44}\n",
      "{'loss': 2.166, 'grad_norm': 1.2712031602859497, 'learning_rate': 1.06318449873631e-05, 'epoch': 2.48}\n",
      "{'loss': 2.0091, 'grad_norm': 2.1160523891448975, 'learning_rate': 1.046335299073294e-05, 'epoch': 2.52}\n",
      "{'loss': 2.252, 'grad_norm': 2.2012104988098145, 'learning_rate': 1.029486099410278e-05, 'epoch': 2.56}\n",
      "{'loss': 2.0129, 'grad_norm': 1.486242413520813, 'learning_rate': 1.012636899747262e-05, 'epoch': 2.6}\n",
      " 52%|████████████████████▊                   | 650/1250 [16:05<14:07,  1.41s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.007546901702881, 'eval_runtime': 0.5073, 'eval_samples_per_second': 19.713, 'eval_steps_per_second': 5.914, 'epoch': 2.6}\n",
      " 52%|████████████████████▊                   | 650/1250 [16:05<14:07,  1.41s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.36it/s]\u001b[A\n",
      "{'loss': 2.0506, 'grad_norm': 1.2526613473892212, 'learning_rate': 9.957877000842461e-06, 'epoch': 2.64}\n",
      "{'loss': 1.7722, 'grad_norm': 1.2446575164794922, 'learning_rate': 9.7893850042123e-06, 'epoch': 2.68}\n",
      "{'loss': 2.0531, 'grad_norm': 2.1876986026763916, 'learning_rate': 9.62089300758214e-06, 'epoch': 2.72}\n",
      "{'loss': 2.0276, 'grad_norm': 1.6396445035934448, 'learning_rate': 9.45240101095198e-06, 'epoch': 2.76}\n",
      "{'loss': 1.9662, 'grad_norm': 1.3345659971237183, 'learning_rate': 9.28390901432182e-06, 'epoch': 2.8}\n",
      " 56%|██████████████████████▍                 | 700/1250 [17:19<13:53,  1.52s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.9744420051574707, 'eval_runtime': 0.5081, 'eval_samples_per_second': 19.681, 'eval_steps_per_second': 5.904, 'epoch': 2.8}\n",
      " 56%|██████████████████████▍                 | 700/1250 [17:19<13:53,  1.52s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.33it/s]\u001b[A\n",
      "{'loss': 1.7606, 'grad_norm': 1.4519704580307007, 'learning_rate': 9.11541701769166e-06, 'epoch': 2.84}\n",
      "{'loss': 2.1567, 'grad_norm': 2.481126308441162, 'learning_rate': 8.9469250210615e-06, 'epoch': 2.88}\n",
      "{'loss': 2.0025, 'grad_norm': 1.8507000207901, 'learning_rate': 8.77843302443134e-06, 'epoch': 2.92}\n",
      "{'loss': 2.177, 'grad_norm': 2.8149776458740234, 'learning_rate': 8.609941027801179e-06, 'epoch': 2.96}\n",
      "{'loss': 1.9745, 'grad_norm': 2.070241689682007, 'learning_rate': 8.44144903117102e-06, 'epoch': 3.0}\n",
      " 60%|████████████████████████                | 750/1250 [18:37<11:57,  1.44s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.9537220001220703, 'eval_runtime': 0.5063, 'eval_samples_per_second': 19.75, 'eval_steps_per_second': 5.925, 'epoch': 3.0}\n",
      " 60%|████████████████████████                | 750/1250 [18:37<11:57,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.39it/s]\u001b[A\n",
      "{'loss': 1.9925, 'grad_norm': 1.0351405143737793, 'learning_rate': 8.272957034540861e-06, 'epoch': 3.04}\n",
      "{'loss': 2.1742, 'grad_norm': 1.992730975151062, 'learning_rate': 8.1044650379107e-06, 'epoch': 3.08}\n",
      "{'loss': 1.9746, 'grad_norm': 1.362880825996399, 'learning_rate': 7.93597304128054e-06, 'epoch': 3.12}\n",
      "{'loss': 1.9763, 'grad_norm': 1.5966074466705322, 'learning_rate': 7.76748104465038e-06, 'epoch': 3.16}\n",
      "{'loss': 1.9654, 'grad_norm': 1.5174206495285034, 'learning_rate': 7.59898904802022e-06, 'epoch': 3.2}\n",
      " 64%|█████████████████████████▌              | 800/1250 [19:49<11:03,  1.47s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.9441285133361816, 'eval_runtime': 0.5086, 'eval_samples_per_second': 19.662, 'eval_steps_per_second': 5.899, 'epoch': 3.2}\n",
      " 64%|█████████████████████████▌              | 800/1250 [19:50<11:03,  1.47s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.31it/s]\u001b[A\n",
      "{'loss': 2.1102, 'grad_norm': 1.5128774642944336, 'learning_rate': 7.43049705139006e-06, 'epoch': 3.24}\n",
      "{'loss': 1.7953, 'grad_norm': 1.925981044769287, 'learning_rate': 7.2620050547598995e-06, 'epoch': 3.28}\n",
      "{'loss': 1.6619, 'grad_norm': 1.9518423080444336, 'learning_rate': 7.09351305812974e-06, 'epoch': 3.32}\n",
      "{'loss': 1.813, 'grad_norm': 1.1802308559417725, 'learning_rate': 6.925021061499579e-06, 'epoch': 3.36}\n",
      "{'loss': 1.8792, 'grad_norm': 1.441292643547058, 'learning_rate': 6.756529064869419e-06, 'epoch': 3.4}\n",
      " 68%|███████████████████████████▏            | 850/1250 [21:07<09:06,  1.37s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.9402451515197754, 'eval_runtime': 0.5078, 'eval_samples_per_second': 19.693, 'eval_steps_per_second': 5.908, 'epoch': 3.4}\n",
      " 68%|███████████████████████████▏            | 850/1250 [21:07<09:06,  1.37s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.34it/s]\u001b[A\n",
      "{'loss': 1.7526, 'grad_norm': 1.6147308349609375, 'learning_rate': 6.588037068239259e-06, 'epoch': 3.44}\n",
      "{'loss': 1.9202, 'grad_norm': 1.0921365022659302, 'learning_rate': 6.419545071609099e-06, 'epoch': 3.48}\n",
      "{'loss': 2.0157, 'grad_norm': 1.5903112888336182, 'learning_rate': 6.251053074978939e-06, 'epoch': 3.52}\n",
      "{'loss': 2.2163, 'grad_norm': 1.3566900491714478, 'learning_rate': 6.082561078348779e-06, 'epoch': 3.56}\n",
      "{'loss': 2.1577, 'grad_norm': 1.6588387489318848, 'learning_rate': 5.914069081718618e-06, 'epoch': 3.6}\n",
      " 72%|████████████████████████████▊           | 900/1250 [22:24<08:51,  1.52s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.9480388164520264, 'eval_runtime': 0.507, 'eval_samples_per_second': 19.723, 'eval_steps_per_second': 5.917, 'epoch': 3.6}\n",
      " 72%|████████████████████████████▊           | 900/1250 [22:24<08:51,  1.52s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.34it/s]\u001b[A\n",
      "{'loss': 1.8093, 'grad_norm': 1.2768895626068115, 'learning_rate': 5.7455770850884585e-06, 'epoch': 3.64}\n",
      "{'loss': 2.2089, 'grad_norm': 4.572997570037842, 'learning_rate': 5.577085088458299e-06, 'epoch': 3.68}\n",
      "{'loss': 2.1818, 'grad_norm': 2.955153226852417, 'learning_rate': 5.408593091828138e-06, 'epoch': 3.72}\n",
      "{'loss': 2.0291, 'grad_norm': 1.4092004299163818, 'learning_rate': 5.240101095197978e-06, 'epoch': 3.76}\n",
      "{'loss': 2.215, 'grad_norm': 1.4574247598648071, 'learning_rate': 5.071609098567818e-06, 'epoch': 3.8}\n",
      " 76%|██████████████████████████████▍         | 950/1250 [23:36<07:03,  1.41s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.9278247356414795, 'eval_runtime': 0.5091, 'eval_samples_per_second': 19.644, 'eval_steps_per_second': 5.893, 'epoch': 3.8}\n",
      " 76%|██████████████████████████████▍         | 950/1250 [23:36<07:03,  1.41s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.32it/s]\u001b[A\n",
      "{'loss': 1.9672, 'grad_norm': 3.050657033920288, 'learning_rate': 4.9031171019376585e-06, 'epoch': 3.84}\n",
      "{'loss': 1.976, 'grad_norm': 1.688425898551941, 'learning_rate': 4.734625105307498e-06, 'epoch': 3.88}\n",
      "{'loss': 1.7622, 'grad_norm': 1.4345498085021973, 'learning_rate': 4.566133108677338e-06, 'epoch': 3.92}\n",
      "{'loss': 1.9185, 'grad_norm': 1.649835467338562, 'learning_rate': 4.397641112047178e-06, 'epoch': 3.96}\n",
      "{'loss': 1.9106, 'grad_norm': 1.7905454635620117, 'learning_rate': 4.2291491154170175e-06, 'epoch': 4.0}\n",
      " 80%|███████████████████████████████▏       | 1000/1250 [24:51<04:52,  1.17s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.912990093231201, 'eval_runtime': 0.5082, 'eval_samples_per_second': 19.677, 'eval_steps_per_second': 5.903, 'epoch': 4.0}\n",
      " 80%|███████████████████████████████▏       | 1000/1250 [24:51<04:52,  1.17s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.30it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 2.0618, 'grad_norm': 2.0252525806427, 'learning_rate': 4.0606571187868585e-06, 'epoch': 4.04}\n",
      "{'loss': 1.7894, 'grad_norm': 1.1458927392959595, 'learning_rate': 3.892165122156698e-06, 'epoch': 4.08}\n",
      "{'loss': 1.7206, 'grad_norm': 1.5305614471435547, 'learning_rate': 3.723673125526538e-06, 'epoch': 4.12}\n",
      "{'loss': 2.0786, 'grad_norm': 5.364130973815918, 'learning_rate': 3.5551811288963777e-06, 'epoch': 4.16}\n",
      "{'loss': 1.9253, 'grad_norm': 1.3008785247802734, 'learning_rate': 3.3866891322662175e-06, 'epoch': 4.2}\n",
      " 84%|████████████████████████████████▊      | 1050/1250 [26:09<04:48,  1.44s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.89396333694458, 'eval_runtime': 0.5063, 'eval_samples_per_second': 19.75, 'eval_steps_per_second': 5.925, 'epoch': 4.2}\n",
      " 84%|████████████████████████████████▊      | 1050/1250 [26:09<04:48,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.37it/s]\u001b[A\n",
      "{'loss': 2.0447, 'grad_norm': 2.4703528881073, 'learning_rate': 3.2181971356360576e-06, 'epoch': 4.24}\n",
      "{'loss': 1.906, 'grad_norm': 1.3603371381759644, 'learning_rate': 3.0497051390058974e-06, 'epoch': 4.28}\n",
      "{'loss': 2.0611, 'grad_norm': 2.1297404766082764, 'learning_rate': 2.881213142375737e-06, 'epoch': 4.32}\n",
      "{'loss': 1.9135, 'grad_norm': 1.7740055322647095, 'learning_rate': 2.7127211457455773e-06, 'epoch': 4.36}\n",
      "{'loss': 2.1161, 'grad_norm': 1.400359034538269, 'learning_rate': 2.544229149115417e-06, 'epoch': 4.4}\n",
      " 88%|██████████████████████████████████▎    | 1100/1250 [27:21<03:19,  1.33s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.9048116207122803, 'eval_runtime': 0.508, 'eval_samples_per_second': 19.684, 'eval_steps_per_second': 5.905, 'epoch': 4.4}\n",
      " 88%|██████████████████████████████████▎    | 1100/1250 [27:21<03:19,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.35it/s]\u001b[A\n",
      "{'loss': 1.8512, 'grad_norm': 1.2762892246246338, 'learning_rate': 2.375737152485257e-06, 'epoch': 4.44}\n",
      "{'loss': 1.897, 'grad_norm': 2.36073637008667, 'learning_rate': 2.207245155855097e-06, 'epoch': 4.48}\n",
      "{'loss': 1.8805, 'grad_norm': 1.8153432607650757, 'learning_rate': 2.038753159224937e-06, 'epoch': 4.52}\n",
      "{'loss': 1.775, 'grad_norm': 1.086173176765442, 'learning_rate': 1.870261162594777e-06, 'epoch': 4.56}\n",
      "{'loss': 1.9551, 'grad_norm': 1.4056724309921265, 'learning_rate': 1.7017691659646168e-06, 'epoch': 4.6}\n",
      " 92%|███████████████████████████████████▉   | 1150/1250 [28:37<02:49,  1.70s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.909097194671631, 'eval_runtime': 0.5079, 'eval_samples_per_second': 19.688, 'eval_steps_per_second': 5.906, 'epoch': 4.6}\n",
      " 92%|███████████████████████████████████▉   | 1150/1250 [28:37<02:49,  1.70s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.33it/s]\u001b[A\n",
      "{'loss': 1.8334, 'grad_norm': 2.3957271575927734, 'learning_rate': 1.5332771693344568e-06, 'epoch': 4.64}\n",
      "{'loss': 1.9648, 'grad_norm': 1.5025825500488281, 'learning_rate': 1.3647851727042965e-06, 'epoch': 4.68}\n",
      "{'loss': 2.0031, 'grad_norm': 2.879751205444336, 'learning_rate': 1.1962931760741365e-06, 'epoch': 4.72}\n",
      "{'loss': 2.1102, 'grad_norm': 1.93034029006958, 'learning_rate': 1.0278011794439766e-06, 'epoch': 4.76}\n",
      "{'loss': 2.0005, 'grad_norm': 2.385708808898926, 'learning_rate': 8.593091828138164e-07, 'epoch': 4.8}\n",
      " 96%|█████████████████████████████████████▍ | 1200/1250 [29:53<01:05,  1.30s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.9076504707336426, 'eval_runtime': 0.5077, 'eval_samples_per_second': 19.696, 'eval_steps_per_second': 5.909, 'epoch': 4.8}\n",
      " 96%|█████████████████████████████████████▍ | 1200/1250 [29:53<01:05,  1.30s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.34it/s]\u001b[A\n",
      "{'loss': 2.0527, 'grad_norm': 1.264547348022461, 'learning_rate': 6.908171861836563e-07, 'epoch': 4.84}\n",
      "{'loss': 2.0408, 'grad_norm': 1.8572760820388794, 'learning_rate': 5.223251895534962e-07, 'epoch': 4.88}\n",
      "{'loss': 1.7774, 'grad_norm': 3.3402960300445557, 'learning_rate': 3.5383319292333613e-07, 'epoch': 4.92}\n",
      "{'loss': 1.8016, 'grad_norm': 2.1806676387786865, 'learning_rate': 1.853411962931761e-07, 'epoch': 4.96}\n",
      "{'loss': 1.5686, 'grad_norm': 2.9865643978118896, 'learning_rate': 1.6849199663016007e-08, 'epoch': 5.0}\n",
      "100%|███████████████████████████████████████| 1250/1250 [31:06<00:00,  1.48s/it]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.9055843353271484, 'eval_runtime': 0.5072, 'eval_samples_per_second': 19.716, 'eval_steps_per_second': 5.915, 'epoch': 5.0}\n",
      "100%|███████████████████████████████████████| 1250/1250 [31:07<00:00,  1.48s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 10.34it/s]\u001b[A\n",
      "{'train_runtime': 1867.3558, 'train_samples_per_second': 2.675, 'train_steps_per_second': 0.669, 'train_loss': 2.0646500980377196, 'epoch': 5.0}\n",
      "100%|███████████████████████████████████████| 1250/1250 [31:07<00:00,  1.49s/it]\n",
      "***** train metrics *****\n",
      "  epoch                    =        5.0\n",
      "  train_loss               =     2.0647\n",
      "  train_runtime            = 0:31:07.35\n",
      "  train_samples            =       1000\n",
      "  train_samples_per_second =      2.675\n",
      "  train_steps_per_second   =      0.669\n",
      "\u001b[32m2024-03-14 16:35:40.726\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1436\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 1867.3558, 'train_samples_per_second': 2.675, 'train_steps_per_second': 0.669, 'train_loss': 2.0646500980377196, 'epoch': 5.0, 'train_samples': 1000}\u001b[0m\n",
      "\u001b[32m2024-03-14 16:35:40.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1437\u001b[0m - \u001b[1mSaving model checkpoint to outputs-sft-v1\u001b[0m\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-03-14 16:35:40.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1445\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  8.68it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        5.0\n",
      "  eval_loss               =     2.9056\n",
      "  eval_runtime            = 0:00:00.50\n",
      "  eval_samples            =         10\n",
      "  eval_samples_per_second =     19.698\n",
      "  eval_steps_per_second   =      5.909\n",
      "  perplexity              =    18.2771\n",
      "\u001b[32m2024-03-14 16:35:41.417\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1458\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 2.9056496620178223, 'eval_runtime': 0.5077, 'eval_samples_per_second': 19.698, 'eval_steps_per_second': 5.909, 'epoch': 5.0, 'eval_samples': 10, 'perplexity': 18.27711374261224}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python supervised_finetuning.py \\\n",
    "    --model_type baichuan \\\n",
    "    --model_name_or_path /data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat \\\n",
    "    --train_file_dir ./data/finetune \\\n",
    "    --validation_file_dir ./data/finetune \\\n",
    "    --per_device_train_batch_size 4 \\\n",
    "    --per_device_eval_batch_size 4 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --use_peft True \\\n",
    "    --fp16 \\\n",
    "    --max_train_samples 1000 \\\n",
    "    --max_eval_samples 10 \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --warmup_ratio 0.05 \\\n",
    "    --weight_decay 0.05 \\\n",
    "    --logging_strategy steps \\\n",
    "    --logging_steps 10 \\\n",
    "    --eval_steps 50 \\\n",
    "    --evaluation_strategy steps \\\n",
    "    --save_steps 500 \\\n",
    "    --save_strategy steps \\\n",
    "    --save_total_limit 3 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --preprocessing_num_workers 1 \\\n",
    "    --output_dir outputs-sft-v1 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --ddp_timeout 30000 \\\n",
    "    --logging_first_step True \\\n",
    "    --target_modules all \\\n",
    "    --lora_rank 8 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --torch_dtype float16 \\\n",
    "    --device_map auto \\\n",
    "    --report_to tensorboard \\\n",
    "    --ddp_find_unused_parameters False \\\n",
    "    --gradient_checkpointing True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 71M\n",
      "-rw-r--r-- 1 root root  714 Mar 14 16:35 adapter_config.json\n",
      "-rw-r--r-- 1 root root  69M Mar 14 16:35 adapter_model.safetensors\n",
      "-rw-r--r-- 1 root root  394 Mar 14 16:35 all_results.json\n",
      "drwxr-xr-x 2 root root  195 Mar 14 16:29 \u001b[0m\u001b[01;34mcheckpoint-1000\u001b[0m/\n",
      "drwxr-xr-x 2 root root  195 Mar 14 16:16 \u001b[01;34mcheckpoint-500\u001b[0m/\n",
      "-rw-r--r-- 1 root root  221 Mar 14 16:35 eval_results.json\n",
      "-rw-r--r-- 1 root root 5.1K Mar 14 16:35 README.md\n",
      "drwxr-xr-x 4 root root  110 Mar 14 16:04 \u001b[01;34mruns\u001b[0m/\n",
      "-rw-r--r-- 1 root root  548 Mar 14 16:35 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root 9.8K Mar 14 16:35 tokenization_baichuan.py\n",
      "-rw-r--r-- 1 root root  968 Mar 14 16:35 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 2.0M Mar 14 16:35 tokenizer.model\n",
      "-rw-r--r-- 1 root root  26K Mar 14 16:35 trainer_state.json\n",
      "-rw-r--r-- 1 root root  193 Mar 14 16:35 train_results.json\n"
     ]
    }
   ],
   "source": [
    "%ls -lh outputs-sft-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "模型训练结果：\n",
    "- 使用lora训练模型，则保存的lora权重是`adapter_model.bin`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
    "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir output-/runs --host 0.0.0.0 --port 8009\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python merge_peft_adapter.py --model_type baichuan \\\n",
    "    --base_model merged-pt --lora_model outputs-sft-v1 --output_dir ./merged-sft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_type='baichuan', base_model='/data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat', tokenizer_path=None, lora_model='outputs-sft-v1', resize_emb=False, output_dir='./merged-sft')\n",
      "Base model: /data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat\n",
      "LoRA model: outputs-sft-v1\n",
      "Loading LoRA for causal language model\n",
      "Merging with merge_and_unload...\n",
      "Saving to Hugging Face format...\n",
      "Done! model saved to ./merged-sft\n"
     ]
    }
   ],
   "source": [
    "!python merge_peft_adapter.py --model_type baichuan \\\n",
    "    --base_model /data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat --lora_model outputs-sft-v1 --output_dir ./merged-sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14G\n",
      "-rw-r--r-- 1 root root  869 Mar 14 15:54 config.json\n",
      "-rw-r--r-- 1 root root 2.4K Mar 14 15:54 configuration_baichuan.py\n",
      "-rw-r--r-- 1 root root  285 Mar 14 15:54 generation_config.json\n",
      "-rw-r--r-- 1 root root 2.9K Mar 14 15:54 generation_utils.py\n",
      "-rw-r--r-- 1 root root  33K Mar 14 15:54 modeling_baichuan.py\n",
      "-rw-r--r-- 1 root root 4.7G Mar 14 15:54 pytorch_model-00001-of-00004.bin\n",
      "-rw-r--r-- 1 root root 4.7G Mar 14 15:54 pytorch_model-00002-of-00004.bin\n",
      "-rw-r--r-- 1 root root 3.8G Mar 14 15:54 pytorch_model-00003-of-00004.bin\n",
      "-rw-r--r-- 1 root root 983M Mar 14 15:55 pytorch_model-00004-of-00004.bin\n",
      "-rw-r--r-- 1 root root  19K Mar 14 15:55 pytorch_model.bin.index.json\n",
      "-rw-r--r-- 1 root root 8.9K Mar 14 15:54 quantizer.py\n",
      "-rw-r--r-- 1 root root  548 Mar 14 15:54 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root 9.8K Mar 14 15:54 tokenization_baichuan.py\n",
      "-rw-r--r-- 1 root root  942 Mar 14 15:54 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 2.0M Mar 14 15:54 tokenizer.model\n"
     ]
    }
   ],
   "source": [
    "%ls -lh merged-sft/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_from_model_config\": true,\n",
      "  \"_name_or_path\": \"merged-pt\",\n",
      "  \"architectures\": [\n",
      "    \"BaichuanForCausalLM\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_baichuan.BaichuanConfig\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_baichuan.BaichuanForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"baichuan\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"BaichuanTokenizer\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.38.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 125696,\n",
      "  \"z_loss_weight\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%cat merged-sft/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Stage2 SFT训练完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T14:07:40.752635Z",
     "start_time": "2023-06-15T14:07:40.731186Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Stage 3: DPO(Direct Preference Optimization)\n",
    "\n",
    "第三阶段：DPO(Direct Preference Optimization)直接偏好优化，DPO通过直接优化语言模型来实现对其行为的精确控制，而无需使用复杂的强化学习，也可以有效学习到人类偏好，DPO相较于RLHF更容易实现且易于训练，效果更好\n",
    "\n",
    "| Stage 3: Direct Preference Optimization        |  [dpo_training.py](https://github.com/shibing624/MedicalGPT/blob/main/dpo_training.py) | [run_dpo.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_dpo.sh)    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 说明：\n",
    "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
    "\n",
    "1. 生成模型：使用的是Bloom的`bigscience/bloomz-560m` 或者 Stage2得到的SFT模型\n",
    "2. 数据集：DPO阶段使用的是医疗reward数据，抽样了500条，位于`data/reward`文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Stage3 咱们开始吧\n",
    "\n",
    "训练步骤如下：\n",
    "\n",
    "1. 确认训练集\n",
    "2. 执行训练脚本\n",
    "\n",
    "训练脚本的执行逻辑如下：\n",
    "1. 导入依赖包\n",
    "2. 设置参数\n",
    "3. 定义各函数并加载训练集\n",
    "4. 加载模型和tokenizer\n",
    "5. 开始训练并评估\n",
    "6. 查看训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.json\n"
     ]
    }
   ],
   "source": [
    "%ls ./data/reward/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-03-14 13:46:34.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mParse args: ScriptArguments(model_type='baichuan', model_name_or_path='./merged-sft', tokenizer_name_or_path=None, load_in_8bit=False, load_in_4bit=False, cache_dir='./cache', use_fast_tokenizer=False, torch_dtype='float16', device_map='auto', trust_remote_code=True, dataset_name=None, dataset_config_name=None, train_file_dir='./data/reward', validation_file_dir='./data/reward', template_name='vicuna', per_device_train_batch_size=3, per_device_eval_batch_size=1, max_source_length=128, max_target_length=128, min_target_length=4, max_train_samples=1000, max_eval_samples=10, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=4, use_peft=True, qlora=False, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, peft_path=None, do_train=True, do_eval=True, beta=0.1, learning_rate=0.0005, lr_scheduler_type='cosine', warmup_steps=100, weight_decay=0.05, optim='adamw_hf', fp16=True, bf16=False, gradient_checkpointing=True, gradient_accumulation_steps=4, save_steps=50, eval_steps=10, logging_steps=1, output_dir='outputs-dpo-v1', max_steps=100, eval_strategy='steps', remove_unused_columns=False, report_to='tensorboard')\u001b[0m\n",
      "\u001b[32m2024-03-14 13:46:35.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m280\u001b[0m - \u001b[1mtrain files: ./data/reward/test.json\u001b[0m\n",
      "\u001b[32m2024-03-14 13:46:35.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1meval files: ./data/reward/test.json\u001b[0m\n",
      "Generating train split: 100 examples [00:00, 32034.71 examples/s]\n",
      "Generating validation split: 100 examples [00:00, 49932.19 examples/s]\n",
      "\u001b[32m2024-03-14 13:46:43.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m306\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'response_chosen', 'response_rejected'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'response_chosen', 'response_rejected'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\u001b[0m\n",
      "\u001b[32m2024-03-14 13:46:43.670\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m324\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'question': '肛门病变可能是什么疾病的症状?', 'response_chosen': '食管克罗恩病', 'response_rejected': '肛门病变可能与多种不同类型的病症有关。'}\u001b[0m\n",
      "Running tokenizer on dataset (num_proc=4): 100%|█| 100/100 [00:00<00:00, 825.92 \n",
      "Filter: 100%|████████████████████████| 100/100 [00:00<00:00, 2779.21 examples/s]\n",
      "\u001b[32m2024-03-14 13:46:43.899\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m337\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 68\u001b[0m\n",
      "\u001b[32m2024-03-14 13:46:43.900\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m338\u001b[0m - \u001b[34m\u001b[1mFirst train example:\u001b[0m\n",
      "\u001b[32m2024-03-14 13:46:43.900\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m339\u001b[0m - \u001b[34m\u001b[1mQuestion: 土源性线虫感染的多发地区是哪里？\n",
      "\n",
      "Answer: 苏北地区；贵州省剑河县；西南贫困地区；桂东；江西省鄱阳湖区；江西省\u001b[0m\n",
      "\u001b[32m2024-03-14 13:46:43.902\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m351\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'question': '肛门病变可能是什么疾病的症状?', 'response_chosen': '食管克罗恩病', 'response_rejected': '肛门病变可能与多种不同类型的病症有关。'}\u001b[0m\n",
      "Running tokenizer on dataset (num_proc=4): 100%|█| 10/10 [00:00<00:00, 93.19 exa\n",
      "Filter: 100%|██████████████████████████| 10/10 [00:00<00:00, 2701.65 examples/s]\n",
      "\u001b[32m2024-03-14 13:46:44.082\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 8\u001b[0m\n",
      "\u001b[32m2024-03-14 13:46:44.082\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m365\u001b[0m - \u001b[34m\u001b[1mFirst eval example:\u001b[0m\n",
      "\u001b[32m2024-03-14 13:46:44.082\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m366\u001b[0m - \u001b[34m\u001b[1mQuestion: 肛门病变可能是什么疾病的症状?\n",
      "\n",
      "Answer: 食管克罗恩病\u001b[0m\n",
      "\u001b[32m2024-03-14 13:46:44.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mDevice map: auto\u001b[0m\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:05<00:00,  1.26s/it]\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "\u001b[32m2024-03-14 13:46:49.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m440\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
      "\u001b[32m2024-03-14 13:46:49.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m444\u001b[0m - \u001b[1mPeft target_modules: ['W_pack', 'down_proj', 'gate_proj', 'o_proj', 'up_proj']\u001b[0m\n",
      "Map: 100%|██████████████████████████████| 68/68 [00:00<00:00, 693.32 examples/s]\n",
      "Map: 100%|████████████████████████████████| 8/8 [00:00<00:00, 509.28 examples/s]\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "trainable params: 17891328 || all params: 7523864576 || trainable%: 0.23779439168895536\n",
      "\u001b[32m2024-03-14 13:46:50.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m471\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
      "{'loss': 0.6931, 'grad_norm': 1.1804450750350952, 'learning_rate': 5e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -47.732582092285156, 'logps/chosen': -88.69464111328125, 'logits/rejected': 9.293362617492676, 'logits/chosen': 8.519160270690918, 'epoch': 0.17}\n",
      "{'loss': 0.6931, 'grad_norm': 1.8812779188156128, 'learning_rate': 1e-05, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -55.88685989379883, 'logps/chosen': -69.40974426269531, 'logits/rejected': 9.89217472076416, 'logits/chosen': 8.18301773071289, 'epoch': 0.35}\n",
      "{'loss': 0.6939, 'grad_norm': 1.8039662837982178, 'learning_rate': 1.5e-05, 'rewards/chosen': -0.0005607128841802478, 'rewards/rejected': 0.0009234666358679533, 'rewards/accuracies': 0.4166666865348816, 'rewards/margins': -0.001484179636463523, 'logps/rejected': -52.62514877319336, 'logps/chosen': -120.83319854736328, 'logits/rejected': 10.408178329467773, 'logits/chosen': 8.148926734924316, 'epoch': 0.52}\n",
      "{'loss': 0.6906, 'grad_norm': 1.4801820516586304, 'learning_rate': 2e-05, 'rewards/chosen': 0.003230285830795765, 'rewards/rejected': -0.00180329498834908, 'rewards/accuracies': 0.9166666865348816, 'rewards/margins': 0.005033580586314201, 'logps/rejected': -69.37372589111328, 'logps/chosen': -104.63512420654297, 'logits/rejected': 9.52296257019043, 'logits/chosen': 8.679937362670898, 'epoch': 0.7}\n",
      "{'loss': 0.6859, 'grad_norm': 2.38451886177063, 'learning_rate': 2.5e-05, 'rewards/chosen': 0.011854171752929688, 'rewards/rejected': -0.0027527017518877983, 'rewards/accuracies': 0.8333333730697632, 'rewards/margins': 0.01460687443614006, 'logps/rejected': -63.301109313964844, 'logps/chosen': -113.55249786376953, 'logits/rejected': 9.756651878356934, 'logits/chosen': 7.842279434204102, 'epoch': 0.87}\n",
      "{'loss': 0.6879, 'grad_norm': 1.365527868270874, 'learning_rate': 3e-05, 'rewards/chosen': 0.0028560878708958626, 'rewards/rejected': -0.007746164686977863, 'rewards/accuracies': 0.9166666865348816, 'rewards/margins': 0.010602252557873726, 'logps/rejected': -53.59765625, 'logps/chosen': -58.08746337890625, 'logits/rejected': 9.984248161315918, 'logits/chosen': 8.37142276763916, 'epoch': 1.04}\n",
      "{'loss': 0.6606, 'grad_norm': 1.5599229335784912, 'learning_rate': 3.5000000000000004e-05, 'rewards/chosen': 0.044942665845155716, 'rewards/rejected': -0.0217122882604599, 'rewards/accuracies': 1.0, 'rewards/margins': 0.06665495783090591, 'logps/rejected': -66.08043670654297, 'logps/chosen': -102.23814392089844, 'logits/rejected': 9.891593933105469, 'logits/chosen': 8.106066703796387, 'epoch': 1.22}\n",
      "{'loss': 0.6577, 'grad_norm': 1.2897388935089111, 'learning_rate': 4e-05, 'rewards/chosen': 0.053758155554533005, 'rewards/rejected': -0.020030802115797997, 'rewards/accuracies': 1.0, 'rewards/margins': 0.07378895580768585, 'logps/rejected': -40.64227294921875, 'logps/chosen': -83.08320617675781, 'logits/rejected': 9.922693252563477, 'logits/chosen': 8.808639526367188, 'epoch': 1.39}\n",
      "{'loss': 0.6182, 'grad_norm': 1.5262714624404907, 'learning_rate': 4.4999999999999996e-05, 'rewards/chosen': 0.09835590422153473, 'rewards/rejected': -0.06287285685539246, 'rewards/accuracies': 1.0, 'rewards/margins': 0.16122877597808838, 'logps/rejected': -69.58523559570312, 'logps/chosen': -151.94631958007812, 'logits/rejected': 9.395652770996094, 'logits/chosen': 7.825465202331543, 'epoch': 1.57}\n",
      "{'loss': 0.5905, 'grad_norm': 1.5017513036727905, 'learning_rate': 5e-05, 'rewards/chosen': 0.15351149439811707, 'rewards/rejected': -0.07287110388278961, 'rewards/accuracies': 1.0, 'rewards/margins': 0.22638258337974548, 'logps/rejected': -61.12986755371094, 'logps/chosen': -107.8510971069336, 'logits/rejected': 9.85690689086914, 'logits/chosen': 7.793385028839111, 'epoch': 1.74}\n",
      " 10%|████▏                                     | 10/100 [00:40<06:17,  4.20s/it]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 2/8 [00:00<00:00,  6.88it/s]\u001b[A\n",
      " 38%|████████████████▉                            | 3/8 [00:00<00:00,  5.63it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 4/8 [00:00<00:00,  4.89it/s]\u001b[A\n",
      " 62%|████████████████████████████▏                | 5/8 [00:01<00:00,  4.52it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 6/8 [00:01<00:00,  4.50it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [00:01<00:00,  3.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.5509599447250366, 'eval_runtime': 2.0442, 'eval_samples_per_second': 3.913, 'eval_steps_per_second': 3.913, 'eval_rewards/chosen': 0.25193890929222107, 'eval_rewards/rejected': -0.08502506464719772, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 0.336963951587677, 'eval_logps/rejected': -41.455291748046875, 'eval_logps/chosen': -91.65306091308594, 'eval_logits/rejected': 9.195404052734375, 'eval_logits/chosen': 8.172415733337402, 'epoch': 1.74}\n",
      " 10%|████▏                                     | 10/100 [00:42<06:17,  4.20s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  3.98it/s]\u001b[A\n",
      "{'loss': 0.5577, 'grad_norm': 1.380500078201294, 'learning_rate': 5.5e-05, 'rewards/chosen': 0.22795835137367249, 'rewards/rejected': -0.09442821890115738, 'rewards/accuracies': 1.0, 'rewards/margins': 0.32238659262657166, 'logps/rejected': -41.94573974609375, 'logps/chosen': -57.26761245727539, 'logits/rejected': 9.459453582763672, 'logits/chosen': 7.684087753295898, 'epoch': 1.91}\n",
      "{'loss': 0.4974, 'grad_norm': 1.2357200384140015, 'learning_rate': 6e-05, 'rewards/chosen': 0.49022945761680603, 'rewards/rejected': -0.16092051565647125, 'rewards/accuracies': 1.0, 'rewards/margins': 0.6511499285697937, 'logps/rejected': -67.92686462402344, 'logps/chosen': -73.10447692871094, 'logits/rejected': 9.242643356323242, 'logits/chosen': 8.483293533325195, 'epoch': 2.09}\n",
      "{'loss': 0.4683, 'grad_norm': 1.2555145025253296, 'learning_rate': 6.500000000000001e-05, 'rewards/chosen': 0.35916826128959656, 'rewards/rejected': -0.20966924726963043, 'rewards/accuracies': 1.0, 'rewards/margins': 0.5688375234603882, 'logps/rejected': -52.128395080566406, 'logps/chosen': -113.87776184082031, 'logits/rejected': 9.782148361206055, 'logits/chosen': 8.668925285339355, 'epoch': 2.26}\n",
      "{'loss': 0.4446, 'grad_norm': 1.05173921585083, 'learning_rate': 7.000000000000001e-05, 'rewards/chosen': 0.41708093881607056, 'rewards/rejected': -0.2630763053894043, 'rewards/accuracies': 1.0, 'rewards/margins': 0.6801572442054749, 'logps/rejected': -64.31636810302734, 'logps/chosen': -85.9654541015625, 'logits/rejected': 9.077064514160156, 'logits/chosen': 7.555185794830322, 'epoch': 2.43}\n",
      "{'loss': 0.4286, 'grad_norm': 1.0564982891082764, 'learning_rate': 7.5e-05, 'rewards/chosen': 0.4836568832397461, 'rewards/rejected': -0.2533460855484009, 'rewards/accuracies': 1.0, 'rewards/margins': 0.737002968788147, 'logps/rejected': -39.186824798583984, 'logps/chosen': -99.03532409667969, 'logits/rejected': 8.870238304138184, 'logits/chosen': 7.841183185577393, 'epoch': 2.61}\n",
      "{'loss': 0.3376, 'grad_norm': 0.9474342465400696, 'learning_rate': 8e-05, 'rewards/chosen': 0.8633345365524292, 'rewards/rejected': -0.4472123384475708, 'rewards/accuracies': 1.0, 'rewards/margins': 1.310546875, 'logps/rejected': -74.99171447753906, 'logps/chosen': -74.50349426269531, 'logits/rejected': 9.255239486694336, 'logits/chosen': 7.214759826660156, 'epoch': 2.78}\n",
      "{'loss': 0.312, 'grad_norm': 0.9081346988677979, 'learning_rate': 8.5e-05, 'rewards/chosen': 0.6913365721702576, 'rewards/rejected': -0.5111050605773926, 'rewards/accuracies': 1.0, 'rewards/margins': 1.202441692352295, 'logps/rejected': -70.86502075195312, 'logps/chosen': -81.34107208251953, 'logits/rejected': 9.588825225830078, 'logits/chosen': 7.31567907333374, 'epoch': 2.96}\n",
      "{'loss': 0.2459, 'grad_norm': 0.9263423085212708, 'learning_rate': 8.999999999999999e-05, 'rewards/chosen': 1.0159484148025513, 'rewards/rejected': -0.6248224377632141, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6407709121704102, 'logps/rejected': -56.02314758300781, 'logps/chosen': -130.5506591796875, 'logits/rejected': 8.495485305786133, 'logits/chosen': 7.29838752746582, 'epoch': 3.13}\n",
      "{'loss': 0.208, 'grad_norm': 0.7102053165435791, 'learning_rate': 9.5e-05, 'rewards/chosen': 0.8954440355300903, 'rewards/rejected': -0.8553249835968018, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7507688999176025, 'logps/rejected': -78.86129760742188, 'logps/chosen': -105.62081146240234, 'logits/rejected': 8.186829566955566, 'logits/chosen': 6.962850570678711, 'epoch': 3.3}\n",
      "{'loss': 0.1712, 'grad_norm': 0.7080166339874268, 'learning_rate': 0.0001, 'rewards/chosen': 1.5224711894989014, 'rewards/rejected': -0.8141118288040161, 'rewards/accuracies': 1.0, 'rewards/margins': 2.336583137512207, 'logps/rejected': -66.84526824951172, 'logps/chosen': -83.211181640625, 'logits/rejected': 7.8092360496521, 'logits/chosen': 6.410536766052246, 'epoch': 3.48}\n",
      " 20%|████████▍                                 | 20/100 [01:21<05:15,  3.94s/it]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 2/8 [00:00<00:00,  6.89it/s]\u001b[A\n",
      " 38%|████████████████▉                            | 3/8 [00:00<00:00,  5.65it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 4/8 [00:00<00:00,  4.90it/s]\u001b[A\n",
      " 62%|████████████████████████████▏                | 5/8 [00:01<00:00,  4.54it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 6/8 [00:01<00:00,  4.52it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [00:01<00:00,  3.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.14113710820674896, 'eval_runtime': 2.0362, 'eval_samples_per_second': 3.929, 'eval_steps_per_second': 3.929, 'eval_rewards/chosen': 1.3166890144348145, 'eval_rewards/rejected': -0.8892199397087097, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 2.205909013748169, 'eval_logps/rejected': -49.49723815917969, 'eval_logps/chosen': -81.00556182861328, 'eval_logits/rejected': 6.729270935058594, 'eval_logits/chosen': 5.9929046630859375, 'epoch': 3.48}\n",
      " 20%|████████▍                                 | 20/100 [01:23<05:15,  3.94s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  3.99it/s]\u001b[A\n",
      "{'loss': 0.1675, 'grad_norm': 0.7049006223678589, 'learning_rate': 0.000105, 'rewards/chosen': 0.6100389957427979, 'rewards/rejected': -1.3130768537521362, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9231159687042236, 'logps/rejected': -69.52137756347656, 'logps/chosen': -51.08453369140625, 'logits/rejected': 7.296132564544678, 'logits/chosen': 6.21389627456665, 'epoch': 3.65}\n",
      "{'loss': 0.1126, 'grad_norm': 0.6789329648017883, 'learning_rate': 0.00011, 'rewards/chosen': 0.9770156145095825, 'rewards/rejected': -1.4699257612228394, 'rewards/accuracies': 1.0, 'rewards/margins': 2.446941375732422, 'logps/rejected': -66.0622329711914, 'logps/chosen': -73.533935546875, 'logits/rejected': 6.812936305999756, 'logits/chosen': 5.631471157073975, 'epoch': 3.83}\n",
      "{'loss': 0.0801, 'grad_norm': 0.5206669569015503, 'learning_rate': 0.000115, 'rewards/chosen': 1.2964112758636475, 'rewards/rejected': -1.481820821762085, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7782320976257324, 'logps/rejected': -56.95611572265625, 'logps/chosen': -82.5048828125, 'logits/rejected': 6.71502685546875, 'logits/chosen': 5.046604633331299, 'epoch': 4.0}\n",
      "{'loss': 0.0427, 'grad_norm': 0.30569812655448914, 'learning_rate': 0.00012, 'rewards/chosen': 2.0847294330596924, 'rewards/rejected': -2.0927329063415527, 'rewards/accuracies': 1.0, 'rewards/margins': 4.177462100982666, 'logps/rejected': -95.33892059326172, 'logps/chosen': -99.18727111816406, 'logits/rejected': 7.050504684448242, 'logits/chosen': 4.9665069580078125, 'epoch': 4.17}\n",
      "{'loss': 0.043, 'grad_norm': 0.4125041961669922, 'learning_rate': 0.000125, 'rewards/chosen': 0.9154070019721985, 'rewards/rejected': -2.5794870853424072, 'rewards/accuracies': 1.0, 'rewards/margins': 3.494894027709961, 'logps/rejected': -80.0538558959961, 'logps/chosen': -74.12071228027344, 'logits/rejected': 5.812585353851318, 'logits/chosen': 5.440844535827637, 'epoch': 4.35}\n",
      "{'loss': 0.0184, 'grad_norm': 0.18731273710727692, 'learning_rate': 0.00013000000000000002, 'rewards/chosen': 1.5343695878982544, 'rewards/rejected': -2.8316283226013184, 'rewards/accuracies': 1.0, 'rewards/margins': 4.365997791290283, 'logps/rejected': -85.58419799804688, 'logps/chosen': -82.92707824707031, 'logits/rejected': 5.161005973815918, 'logits/chosen': 4.454620361328125, 'epoch': 4.52}\n",
      "{'loss': 0.0183, 'grad_norm': 0.17416614294052124, 'learning_rate': 0.000135, 'rewards/chosen': 1.5012001991271973, 'rewards/rejected': -3.356459617614746, 'rewards/accuracies': 1.0, 'rewards/margins': 4.857660293579102, 'logps/rejected': -99.33999633789062, 'logps/chosen': -66.95578002929688, 'logits/rejected': 5.187993049621582, 'logits/chosen': 3.623629093170166, 'epoch': 4.7}\n",
      "{'loss': 0.0941, 'grad_norm': 1.4332317113876343, 'learning_rate': 0.00014000000000000001, 'rewards/chosen': 0.973183810710907, 'rewards/rejected': -2.6088287830352783, 'rewards/accuracies': 0.9166666865348816, 'rewards/margins': 3.58201265335083, 'logps/rejected': -66.5164566040039, 'logps/chosen': -86.02816009521484, 'logits/rejected': 4.507568359375, 'logits/chosen': 4.119283676147461, 'epoch': 4.87}\n",
      "{'loss': 0.0368, 'grad_norm': 0.5042774081230164, 'learning_rate': 0.000145, 'rewards/chosen': 0.8412026762962341, 'rewards/rejected': -3.1533517837524414, 'rewards/accuracies': 1.0, 'rewards/margins': 3.9945547580718994, 'logps/rejected': -72.38682556152344, 'logps/chosen': -74.1904525756836, 'logits/rejected': 4.381469249725342, 'logits/chosen': 4.204131126403809, 'epoch': 5.04}\n",
      "{'loss': 0.0244, 'grad_norm': 0.3592899739742279, 'learning_rate': 0.00015, 'rewards/chosen': 1.3343253135681152, 'rewards/rejected': -4.060393333435059, 'rewards/accuracies': 1.0, 'rewards/margins': 5.394718647003174, 'logps/rejected': -106.67623901367188, 'logps/chosen': -118.25444793701172, 'logits/rejected': 4.518772125244141, 'logits/chosen': 3.456247329711914, 'epoch': 5.22}\n",
      " 30%|████████████▌                             | 30/100 [02:00<04:29,  3.85s/it]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 2/8 [00:00<00:00,  6.88it/s]\u001b[A\n",
      " 38%|████████████████▉                            | 3/8 [00:00<00:00,  5.64it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 4/8 [00:00<00:00,  4.89it/s]\u001b[A\n",
      " 62%|████████████████████████████▏                | 5/8 [00:01<00:00,  4.53it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 6/8 [00:01<00:00,  4.51it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [00:01<00:00,  3.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.010533432476222515, 'eval_runtime': 2.0549, 'eval_samples_per_second': 3.893, 'eval_steps_per_second': 3.893, 'eval_rewards/chosen': 1.774448037147522, 'eval_rewards/rejected': -3.200087308883667, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 4.9745354652404785, 'eval_logps/rejected': -72.60591125488281, 'eval_logps/chosen': -76.42796325683594, 'eval_logits/rejected': 3.0585670471191406, 'eval_logits/chosen': 2.4652276039123535, 'epoch': 5.22}\n",
      " 30%|████████████▌                             | 30/100 [02:02<04:29,  3.85s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  3.99it/s]\u001b[A\n",
      "{'loss': 0.009, 'grad_norm': 0.0929093062877655, 'learning_rate': 0.000155, 'rewards/chosen': 2.005636692047119, 'rewards/rejected': -3.4440605640411377, 'rewards/accuracies': 1.0, 'rewards/margins': 5.449697494506836, 'logps/rejected': -88.8789291381836, 'logps/chosen': -89.59247589111328, 'logits/rejected': 3.7526488304138184, 'logits/chosen': 2.896472215652466, 'epoch': 5.39}\n",
      "{'loss': 0.0051, 'grad_norm': 0.08143570274114609, 'learning_rate': 0.00016, 'rewards/chosen': 1.3179980516433716, 'rewards/rejected': -5.269726753234863, 'rewards/accuracies': 1.0, 'rewards/margins': 6.5877251625061035, 'logps/rejected': -126.4905776977539, 'logps/chosen': -109.20376586914062, 'logits/rejected': 3.2732303142547607, 'logits/chosen': 2.1118524074554443, 'epoch': 5.57}\n",
      "{'loss': 0.0029, 'grad_norm': 0.036230362951755524, 'learning_rate': 0.000165, 'rewards/chosen': 1.611831545829773, 'rewards/rejected': -4.588730812072754, 'rewards/accuracies': 1.0, 'rewards/margins': 6.200562000274658, 'logps/rejected': -103.23692321777344, 'logps/chosen': -74.98812866210938, 'logits/rejected': 3.2035584449768066, 'logits/chosen': 2.5134825706481934, 'epoch': 5.74}\n",
      "{'loss': 0.0076, 'grad_norm': 0.06550730764865875, 'learning_rate': 0.00017, 'rewards/chosen': 1.1388065814971924, 'rewards/rejected': -4.219647407531738, 'rewards/accuracies': 1.0, 'rewards/margins': 5.358453750610352, 'logps/rejected': -80.49922943115234, 'logps/chosen': -45.13018035888672, 'logits/rejected': 1.4939035177230835, 'logits/chosen': 1.5344629287719727, 'epoch': 5.91}\n",
      "{'loss': 0.0076, 'grad_norm': 0.0850846916437149, 'learning_rate': 0.000175, 'rewards/chosen': 2.0476791858673096, 'rewards/rejected': -4.4675068855285645, 'rewards/accuracies': 1.0, 'rewards/margins': 6.515186309814453, 'logps/rejected': -97.10272979736328, 'logps/chosen': -51.48176574707031, 'logits/rejected': 2.7943532466888428, 'logits/chosen': 2.2792234420776367, 'epoch': 6.09}\n",
      "{'loss': 0.0033, 'grad_norm': 0.03724687546491623, 'learning_rate': 0.00017999999999999998, 'rewards/chosen': 1.2759249210357666, 'rewards/rejected': -5.004611492156982, 'rewards/accuracies': 1.0, 'rewards/margins': 6.280536651611328, 'logps/rejected': -92.38487243652344, 'logps/chosen': -56.30192947387695, 'logits/rejected': 1.3526142835617065, 'logits/chosen': 1.1294443607330322, 'epoch': 6.26}\n",
      "{'loss': 0.0016, 'grad_norm': 0.017429033294320107, 'learning_rate': 0.000185, 'rewards/chosen': 1.8631889820098877, 'rewards/rejected': -5.649064064025879, 'rewards/accuracies': 1.0, 'rewards/margins': 7.5122528076171875, 'logps/rejected': -120.7201919555664, 'logps/chosen': -86.52909088134766, 'logits/rejected': 1.299174189567566, 'logits/chosen': 0.9424079656600952, 'epoch': 6.43}\n",
      "{'loss': 0.0011, 'grad_norm': 0.015427426435053349, 'learning_rate': 0.00019, 'rewards/chosen': 1.7309828996658325, 'rewards/rejected': -5.625548839569092, 'rewards/accuracies': 1.0, 'rewards/margins': 7.356531620025635, 'logps/rejected': -112.06187438964844, 'logps/chosen': -100.21775817871094, 'logits/rejected': 1.052290439605713, 'logits/chosen': 0.37063920497894287, 'epoch': 6.61}\n",
      "{'loss': 0.0009, 'grad_norm': 0.011917628347873688, 'learning_rate': 0.00019500000000000002, 'rewards/chosen': 1.3974206447601318, 'rewards/rejected': -6.385400295257568, 'rewards/accuracies': 1.0, 'rewards/margins': 7.782821178436279, 'logps/rejected': -136.09136962890625, 'logps/chosen': -113.25042724609375, 'logits/rejected': 1.2530794143676758, 'logits/chosen': 0.6387407779693604, 'epoch': 6.78}\n",
      "{'loss': 0.0026, 'grad_norm': 0.03624306619167328, 'learning_rate': 0.0002, 'rewards/chosen': 1.4764734506607056, 'rewards/rejected': -5.906023025512695, 'rewards/accuracies': 1.0, 'rewards/margins': 7.382495880126953, 'logps/rejected': -110.00906372070312, 'logps/chosen': -64.11860656738281, 'logits/rejected': -0.01573273539543152, 'logits/chosen': -0.706047773361206, 'epoch': 6.96}\n",
      " 40%|████████████████▊                         | 40/100 [02:39<03:50,  3.84s/it]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 2/8 [00:00<00:00,  6.88it/s]\u001b[A\n",
      " 38%|████████████████▉                            | 3/8 [00:00<00:00,  5.64it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 4/8 [00:00<00:00,  4.90it/s]\u001b[A\n",
      " 62%|████████████████████████████▏                | 5/8 [00:01<00:00,  4.54it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 6/8 [00:01<00:00,  4.51it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [00:01<00:00,  3.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.002102356404066086, 'eval_runtime': 2.0376, 'eval_samples_per_second': 3.926, 'eval_steps_per_second': 3.926, 'eval_rewards/chosen': 2.30501389503479, 'eval_rewards/rejected': -4.876018524169922, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 7.181032180786133, 'eval_logps/rejected': -89.36521911621094, 'eval_logps/chosen': -71.12230682373047, 'eval_logits/rejected': -0.7794746160507202, 'eval_logits/chosen': -0.8622324466705322, 'epoch': 6.96}\n",
      " 40%|████████████████▊                         | 40/100 [02:41<03:50,  3.84s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  3.99it/s]\u001b[A\n",
      "{'loss': 0.0006, 'grad_norm': 0.01098173949867487, 'learning_rate': 0.000205, 'rewards/chosen': 2.036581039428711, 'rewards/rejected': -6.75363826751709, 'rewards/accuracies': 1.0, 'rewards/margins': 8.790218353271484, 'logps/rejected': -129.91876220703125, 'logps/chosen': -86.86595916748047, 'logits/rejected': -0.02917003631591797, 'logits/chosen': 0.24203354120254517, 'epoch': 7.13}\n",
      "{'loss': 0.0007, 'grad_norm': 0.009336489252746105, 'learning_rate': 0.00021, 'rewards/chosen': 1.3934485912322998, 'rewards/rejected': -7.145960807800293, 'rewards/accuracies': 1.0, 'rewards/margins': 8.539409637451172, 'logps/rejected': -129.5702362060547, 'logps/chosen': -42.308475494384766, 'logits/rejected': 0.15960541367530823, 'logits/chosen': -0.6971918344497681, 'epoch': 7.3}\n",
      "{'loss': 0.001, 'grad_norm': 0.02120906300842762, 'learning_rate': 0.000215, 'rewards/chosen': 1.7665635347366333, 'rewards/rejected': -5.872688293457031, 'rewards/accuracies': 1.0, 'rewards/margins': 7.639251708984375, 'logps/rejected': -102.76296997070312, 'logps/chosen': -48.43120574951172, 'logits/rejected': -1.2871769666671753, 'logits/chosen': -1.910826563835144, 'epoch': 7.48}\n",
      "{'loss': 0.0008, 'grad_norm': 0.013431943953037262, 'learning_rate': 0.00022, 'rewards/chosen': 1.08009934425354, 'rewards/rejected': -7.103281021118164, 'rewards/accuracies': 1.0, 'rewards/margins': 8.183381080627441, 'logps/rejected': -133.32174682617188, 'logps/chosen': -96.23318481445312, 'logits/rejected': -1.126278042793274, 'logits/chosen': -1.598604440689087, 'epoch': 7.65}\n",
      "{'loss': 0.0008, 'grad_norm': 0.016046641394495964, 'learning_rate': 0.00022500000000000002, 'rewards/chosen': 1.6919552087783813, 'rewards/rejected': -6.752834320068359, 'rewards/accuracies': 1.0, 'rewards/margins': 8.444790840148926, 'logps/rejected': -121.16697692871094, 'logps/chosen': -113.85360717773438, 'logits/rejected': -0.9506514072418213, 'logits/chosen': -1.035426378250122, 'epoch': 7.83}\n",
      "{'loss': 0.0008, 'grad_norm': 0.011839921586215496, 'learning_rate': 0.00023, 'rewards/chosen': 0.9313105344772339, 'rewards/rejected': -7.350174903869629, 'rewards/accuracies': 1.0, 'rewards/margins': 8.281485557556152, 'logps/rejected': -132.4002227783203, 'logps/chosen': -90.87640380859375, 'logits/rejected': -1.005938172340393, 'logits/chosen': -1.4252184629440308, 'epoch': 8.0}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011080167256295681, 'learning_rate': 0.000235, 'rewards/chosen': 0.8141995072364807, 'rewards/rejected': -7.830358028411865, 'rewards/accuracies': 1.0, 'rewards/margins': 8.64455795288086, 'logps/rejected': -142.12762451171875, 'logps/chosen': -94.10443115234375, 'logits/rejected': -1.2626957893371582, 'logits/chosen': -1.8930392265319824, 'epoch': 8.17}\n",
      "{'loss': 0.0003, 'grad_norm': 0.008321903645992279, 'learning_rate': 0.00024, 'rewards/chosen': 0.965202808380127, 'rewards/rejected': -8.133458137512207, 'rewards/accuracies': 1.0, 'rewards/margins': 9.098661422729492, 'logps/rejected': -123.01478576660156, 'logps/chosen': -33.178611755371094, 'logits/rejected': -3.3880810737609863, 'logits/chosen': -2.4665040969848633, 'epoch': 8.35}\n",
      "{'loss': 0.0004, 'grad_norm': 0.010198162868618965, 'learning_rate': 0.000245, 'rewards/chosen': 0.82562655210495, 'rewards/rejected': -8.454160690307617, 'rewards/accuracies': 1.0, 'rewards/margins': 9.279787063598633, 'logps/rejected': -152.92678833007812, 'logps/chosen': -150.96661376953125, 'logits/rejected': -1.8817808628082275, 'logits/chosen': -2.098069906234741, 'epoch': 8.52}\n",
      "{'loss': 0.0003, 'grad_norm': 0.00558423763141036, 'learning_rate': 0.00025, 'rewards/chosen': 1.2228827476501465, 'rewards/rejected': -8.288999557495117, 'rewards/accuracies': 1.0, 'rewards/margins': 9.511882781982422, 'logps/rejected': -146.5513916015625, 'logps/chosen': -93.2503890991211, 'logits/rejected': -2.635805368423462, 'logits/chosen': -2.4935014247894287, 'epoch': 8.7}\n",
      " 50%|█████████████████████                     | 50/100 [03:19<03:09,  3.79s/it]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 2/8 [00:00<00:00,  6.87it/s]\u001b[A\n",
      " 38%|████████████████▉                            | 3/8 [00:00<00:00,  5.63it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 4/8 [00:00<00:00,  4.89it/s]\u001b[A\n",
      " 62%|████████████████████████████▏                | 5/8 [00:01<00:00,  4.53it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 6/8 [00:01<00:00,  4.51it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [00:01<00:00,  3.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.00047530620940960944, 'eval_runtime': 2.04, 'eval_samples_per_second': 3.922, 'eval_steps_per_second': 3.922, 'eval_rewards/chosen': 2.3688931465148926, 'eval_rewards/rejected': -6.456292629241943, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 8.825185775756836, 'eval_logps/rejected': -105.16796875, 'eval_logps/chosen': -70.4835205078125, 'eval_logits/rejected': -3.8364510536193848, 'eval_logits/chosen': -3.515697956085205, 'epoch': 8.7}\n",
      " 50%|█████████████████████                     | 50/100 [03:21<03:09,  3.79s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  3.98it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in ./merged-sft - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 0.0004, 'grad_norm': 0.00593985803425312, 'learning_rate': 0.000255, 'rewards/chosen': 1.8070738315582275, 'rewards/rejected': -7.669180870056152, 'rewards/accuracies': 1.0, 'rewards/margins': 9.476255416870117, 'logps/rejected': -130.60153198242188, 'logps/chosen': -37.0058708190918, 'logits/rejected': -2.8510053157806396, 'logits/chosen': -3.612788200378418, 'epoch': 8.87}\n",
      "{'loss': 0.0005, 'grad_norm': 0.026536602526903152, 'learning_rate': 0.00026000000000000003, 'rewards/chosen': 1.8592685461044312, 'rewards/rejected': -7.163025856018066, 'rewards/accuracies': 1.0, 'rewards/margins': 9.022294044494629, 'logps/rejected': -123.33976745605469, 'logps/chosen': -88.51911926269531, 'logits/rejected': -2.8210160732269287, 'logits/chosen': -3.8702783584594727, 'epoch': 9.04}\n",
      "{'loss': 0.0003, 'grad_norm': 0.0063746338710188866, 'learning_rate': 0.00026500000000000004, 'rewards/chosen': 0.9133589863777161, 'rewards/rejected': -8.974966049194336, 'rewards/accuracies': 1.0, 'rewards/margins': 9.888324737548828, 'logps/rejected': -153.17604064941406, 'logps/chosen': -114.5261459350586, 'logits/rejected': -2.6940500736236572, 'logits/chosen': -2.7068026065826416, 'epoch': 9.22}\n",
      "{'loss': 0.0002, 'grad_norm': 0.005511390045285225, 'learning_rate': 0.00027, 'rewards/chosen': 0.7156811952590942, 'rewards/rejected': -8.665327072143555, 'rewards/accuracies': 1.0, 'rewards/margins': 9.38100814819336, 'logps/rejected': -134.8367919921875, 'logps/chosen': -78.93670654296875, 'logits/rejected': -3.1713321208953857, 'logits/chosen': -2.8091888427734375, 'epoch': 9.39}\n",
      "{'loss': 0.0003, 'grad_norm': 0.011471805162727833, 'learning_rate': 0.000275, 'rewards/chosen': 1.7895805835723877, 'rewards/rejected': -8.215100288391113, 'rewards/accuracies': 1.0, 'rewards/margins': 10.004680633544922, 'logps/rejected': -133.12179565429688, 'logps/chosen': -91.2997817993164, 'logits/rejected': -2.964280366897583, 'logits/chosen': -2.957475423812866, 'epoch': 9.57}\n",
      "{'loss': 0.0003, 'grad_norm': 0.005922324489802122, 'learning_rate': 0.00028000000000000003, 'rewards/chosen': 1.0367296934127808, 'rewards/rejected': -8.344175338745117, 'rewards/accuracies': 1.0, 'rewards/margins': 9.380905151367188, 'logps/rejected': -139.95919799804688, 'logps/chosen': -78.51463317871094, 'logits/rejected': -4.015704154968262, 'logits/chosen': -4.182440757751465, 'epoch': 9.74}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0046440730802714825, 'learning_rate': 0.000285, 'rewards/chosen': 1.2313178777694702, 'rewards/rejected': -8.98508071899414, 'rewards/accuracies': 1.0, 'rewards/margins': 10.216400146484375, 'logps/rejected': -142.7674560546875, 'logps/chosen': -59.543373107910156, 'logits/rejected': -3.2694015502929688, 'logits/chosen': -3.910646677017212, 'epoch': 9.91}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0026151554193347692, 'learning_rate': 0.00029, 'rewards/chosen': 0.6692746877670288, 'rewards/rejected': -9.670480728149414, 'rewards/accuracies': 1.0, 'rewards/margins': 10.339755058288574, 'logps/rejected': -152.79547119140625, 'logps/chosen': -100.7655029296875, 'logits/rejected': -3.9120614528656006, 'logits/chosen': -3.5364885330200195, 'epoch': 10.09}\n",
      "{'loss': 0.0002, 'grad_norm': 0.005150128621608019, 'learning_rate': 0.000295, 'rewards/chosen': 0.6979572176933289, 'rewards/rejected': -9.140433311462402, 'rewards/accuracies': 1.0, 'rewards/margins': 9.838390350341797, 'logps/rejected': -143.58541870117188, 'logps/chosen': -63.567039489746094, 'logits/rejected': -3.9708781242370605, 'logits/chosen': -4.231408596038818, 'epoch': 10.26}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0031681840773671865, 'learning_rate': 0.0003, 'rewards/chosen': 0.7133889198303223, 'rewards/rejected': -10.286612510681152, 'rewards/accuracies': 1.0, 'rewards/margins': 11.000001907348633, 'logps/rejected': -172.89418029785156, 'logps/chosen': -82.14422607421875, 'logits/rejected': -3.836271047592163, 'logits/chosen': -4.376249313354492, 'epoch': 10.43}\n",
      " 60%|█████████████████████████▏                | 60/100 [03:59<02:27,  3.68s/it]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 2/8 [00:00<00:00,  6.89it/s]\u001b[A\n",
      " 38%|████████████████▉                            | 3/8 [00:00<00:00,  5.64it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 4/8 [00:00<00:00,  4.89it/s]\u001b[A\n",
      " 62%|████████████████████████████▏                | 5/8 [00:01<00:00,  4.53it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 6/8 [00:01<00:00,  4.51it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [00:01<00:00,  3.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.00015871859795879573, 'eval_runtime': 2.0374, 'eval_samples_per_second': 3.927, 'eval_steps_per_second': 3.927, 'eval_rewards/chosen': 2.4429759979248047, 'eval_rewards/rejected': -7.4493513107299805, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 9.892328262329102, 'eval_logps/rejected': -115.09855651855469, 'eval_logps/chosen': -69.74268341064453, 'eval_logits/rejected': -5.221620559692383, 'eval_logits/chosen': -4.658788681030273, 'epoch': 10.43}\n",
      " 60%|█████████████████████████▏                | 60/100 [04:01<02:27,  3.68s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  3.99it/s]\u001b[A\n",
      "{'loss': 0.0001, 'grad_norm': 0.0033179298043251038, 'learning_rate': 0.000305, 'rewards/chosen': 1.0765581130981445, 'rewards/rejected': -8.922944068908691, 'rewards/accuracies': 1.0, 'rewards/margins': 9.999502182006836, 'logps/rejected': -143.97959899902344, 'logps/chosen': -122.13616943359375, 'logits/rejected': -3.3327314853668213, 'logits/chosen': -4.116879463195801, 'epoch': 10.61}\n",
      "{'loss': 0.0001, 'grad_norm': 0.002814953215420246, 'learning_rate': 0.00031, 'rewards/chosen': 0.4966644048690796, 'rewards/rejected': -10.189643859863281, 'rewards/accuracies': 1.0, 'rewards/margins': 10.686307907104492, 'logps/rejected': -167.06590270996094, 'logps/chosen': -116.15408325195312, 'logits/rejected': -4.235560894012451, 'logits/chosen': -4.359282493591309, 'epoch': 10.78}\n",
      "{'loss': 0.0001, 'grad_norm': 0.002891378477215767, 'learning_rate': 0.000315, 'rewards/chosen': 1.7177634239196777, 'rewards/rejected': -8.735493659973145, 'rewards/accuracies': 1.0, 'rewards/margins': 10.453256607055664, 'logps/rejected': -141.1800994873047, 'logps/chosen': -53.83143615722656, 'logits/rejected': -4.098354816436768, 'logits/chosen': -4.8522233963012695, 'epoch': 10.96}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0036988018546253443, 'learning_rate': 0.00032, 'rewards/chosen': 0.9596239328384399, 'rewards/rejected': -8.67697525024414, 'rewards/accuracies': 1.0, 'rewards/margins': 9.636598587036133, 'logps/rejected': -129.8569793701172, 'logps/chosen': -71.02411651611328, 'logits/rejected': -4.294554710388184, 'logits/chosen': -3.7012763023376465, 'epoch': 11.13}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0026704641059041023, 'learning_rate': 0.00032500000000000004, 'rewards/chosen': 0.7133455276489258, 'rewards/rejected': -9.711527824401855, 'rewards/accuracies': 1.0, 'rewards/margins': 10.424873352050781, 'logps/rejected': -156.29588317871094, 'logps/chosen': -91.13618469238281, 'logits/rejected': -4.208731174468994, 'logits/chosen': -3.9489622116088867, 'epoch': 11.3}\n",
      "{'loss': 0.0001, 'grad_norm': 0.002834721701219678, 'learning_rate': 0.00033, 'rewards/chosen': 1.762009620666504, 'rewards/rejected': -8.904863357543945, 'rewards/accuracies': 1.0, 'rewards/margins': 10.666873931884766, 'logps/rejected': -134.48135375976562, 'logps/chosen': -63.33106231689453, 'logits/rejected': -3.9183757305145264, 'logits/chosen': -4.346579074859619, 'epoch': 11.48}\n",
      "{'loss': 0.0001, 'grad_norm': 0.001904462231323123, 'learning_rate': 0.000335, 'rewards/chosen': 0.9153026342391968, 'rewards/rejected': -10.071842193603516, 'rewards/accuracies': 1.0, 'rewards/margins': 10.98714542388916, 'logps/rejected': -156.14154052734375, 'logps/chosen': -69.30460357666016, 'logits/rejected': -4.353729724884033, 'logits/chosen': -4.54039192199707, 'epoch': 11.65}\n",
      "{'loss': 0.0001, 'grad_norm': 0.002038634615018964, 'learning_rate': 0.00034, 'rewards/chosen': 1.8895142078399658, 'rewards/rejected': -9.597434997558594, 'rewards/accuracies': 1.0, 'rewards/margins': 11.486948013305664, 'logps/rejected': -149.94180297851562, 'logps/chosen': -84.2096176147461, 'logits/rejected': -4.589351654052734, 'logits/chosen': -4.509943962097168, 'epoch': 11.83}\n",
      "{'loss': 0.0, 'grad_norm': 0.001089776400476694, 'learning_rate': 0.000345, 'rewards/chosen': -0.7172324061393738, 'rewards/rejected': -11.389376640319824, 'rewards/accuracies': 1.0, 'rewards/margins': 10.672144889831543, 'logps/rejected': -189.53639221191406, 'logps/chosen': -139.1197967529297, 'logits/rejected': -4.085131645202637, 'logits/chosen': -4.366868495941162, 'epoch': 12.0}\n",
      "{'loss': 0.0, 'grad_norm': 0.0014702725457027555, 'learning_rate': 0.00035, 'rewards/chosen': 1.9625736474990845, 'rewards/rejected': -9.386689186096191, 'rewards/accuracies': 1.0, 'rewards/margins': 11.349262237548828, 'logps/rejected': -148.83364868164062, 'logps/chosen': -96.86734771728516, 'logits/rejected': -4.315435409545898, 'logits/chosen': -4.897364616394043, 'epoch': 12.17}\n",
      " 70%|█████████████████████████████▍            | 70/100 [04:40<02:00,  4.02s/it]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 2/8 [00:00<00:00,  6.88it/s]\u001b[A\n",
      " 38%|████████████████▉                            | 3/8 [00:00<00:00,  5.64it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 4/8 [00:00<00:00,  4.89it/s]\u001b[A\n",
      " 62%|████████████████████████████▏                | 5/8 [00:01<00:00,  4.53it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 6/8 [00:01<00:00,  4.51it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [00:01<00:00,  3.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 7.16478461981751e-05, 'eval_runtime': 2.0395, 'eval_samples_per_second': 3.922, 'eval_steps_per_second': 3.922, 'eval_rewards/chosen': 2.584078788757324, 'eval_rewards/rejected': -8.094536781311035, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 10.678614616394043, 'eval_logps/rejected': -121.55039978027344, 'eval_logps/chosen': -68.33165740966797, 'eval_logits/rejected': -5.752650260925293, 'eval_logits/chosen': -5.050518035888672, 'epoch': 12.17}\n",
      " 70%|█████████████████████████████▍            | 70/100 [04:42<02:00,  4.02s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  3.99it/s]\u001b[A\n",
      "{'loss': 0.0, 'grad_norm': 0.001045587589032948, 'learning_rate': 0.000355, 'rewards/chosen': 0.3438238799571991, 'rewards/rejected': -11.992877960205078, 'rewards/accuracies': 1.0, 'rewards/margins': 12.336702346801758, 'logps/rejected': -190.76788330078125, 'logps/chosen': -102.92689514160156, 'logits/rejected': -3.991530418395996, 'logits/chosen': -4.600147724151611, 'epoch': 12.35}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0025413890834897757, 'learning_rate': 0.00035999999999999997, 'rewards/chosen': 0.8882994651794434, 'rewards/rejected': -8.949440956115723, 'rewards/accuracies': 1.0, 'rewards/margins': 9.83774185180664, 'logps/rejected': -155.17982482910156, 'logps/chosen': -114.23997497558594, 'logits/rejected': -3.692178249359131, 'logits/chosen': -4.340019226074219, 'epoch': 12.52}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0016858266899362206, 'learning_rate': 0.000365, 'rewards/chosen': 0.8695079684257507, 'rewards/rejected': -9.366691589355469, 'rewards/accuracies': 1.0, 'rewards/margins': 10.236200332641602, 'logps/rejected': -124.41181182861328, 'logps/chosen': -29.685230255126953, 'logits/rejected': -5.511667251586914, 'logits/chosen': -4.817693710327148, 'epoch': 12.7}\n",
      "{'loss': 0.0, 'grad_norm': 0.0008197654387913644, 'learning_rate': 0.00037, 'rewards/chosen': 0.8761426210403442, 'rewards/rejected': -10.799566268920898, 'rewards/accuracies': 1.0, 'rewards/margins': 11.675708770751953, 'logps/rejected': -164.3120574951172, 'logps/chosen': -86.88333129882812, 'logits/rejected': -4.922872066497803, 'logits/chosen': -4.695046424865723, 'epoch': 12.87}\n",
      "{'loss': 0.0, 'grad_norm': 0.0011603788007050753, 'learning_rate': 0.000375, 'rewards/chosen': 0.49732476472854614, 'rewards/rejected': -10.557943344116211, 'rewards/accuracies': 1.0, 'rewards/margins': 11.055267333984375, 'logps/rejected': -168.89434814453125, 'logps/chosen': -96.43722534179688, 'logits/rejected': -4.061519622802734, 'logits/chosen': -4.316831588745117, 'epoch': 13.04}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006020255386829376, 'learning_rate': 0.00038, 'rewards/chosen': 1.7693207263946533, 'rewards/rejected': -10.603803634643555, 'rewards/accuracies': 1.0, 'rewards/margins': 12.373123168945312, 'logps/rejected': -159.06573486328125, 'logps/chosen': -90.40435791015625, 'logits/rejected': -4.397555351257324, 'logits/chosen': -4.324489116668701, 'epoch': 13.22}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0017619706923142076, 'learning_rate': 0.00038500000000000003, 'rewards/chosen': 0.39985454082489014, 'rewards/rejected': -10.340008735656738, 'rewards/accuracies': 1.0, 'rewards/margins': 10.739863395690918, 'logps/rejected': -147.86598205566406, 'logps/chosen': -75.60366821289062, 'logits/rejected': -4.483290195465088, 'logits/chosen': -4.314701080322266, 'epoch': 13.39}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0013797410065308213, 'learning_rate': 0.00039000000000000005, 'rewards/chosen': 0.7587956190109253, 'rewards/rejected': -11.245771408081055, 'rewards/accuracies': 1.0, 'rewards/margins': 12.004566192626953, 'logps/rejected': -164.7526397705078, 'logps/chosen': -62.115966796875, 'logits/rejected': -4.792964458465576, 'logits/chosen': -4.6809186935424805, 'epoch': 13.57}\n",
      "{'loss': 0.0, 'grad_norm': 0.0007785572670400143, 'learning_rate': 0.000395, 'rewards/chosen': 1.2770479917526245, 'rewards/rejected': -10.406262397766113, 'rewards/accuracies': 1.0, 'rewards/margins': 11.683310508728027, 'logps/rejected': -177.74032592773438, 'logps/chosen': -104.20126342773438, 'logits/rejected': -4.131865501403809, 'logits/chosen': -4.997378349304199, 'epoch': 13.74}\n",
      "{'loss': 0.0, 'grad_norm': 0.0008957124082371593, 'learning_rate': 0.0004, 'rewards/chosen': 1.395463228225708, 'rewards/rejected': -9.394190788269043, 'rewards/accuracies': 1.0, 'rewards/margins': 10.789653778076172, 'logps/rejected': -144.04934692382812, 'logps/chosen': -80.42699432373047, 'logits/rejected': -4.528209686279297, 'logits/chosen': -4.491889953613281, 'epoch': 13.91}\n",
      " 80%|█████████████████████████████████▌        | 80/100 [05:20<01:16,  3.83s/it]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 2/8 [00:00<00:00,  6.88it/s]\u001b[A\n",
      " 38%|████████████████▉                            | 3/8 [00:00<00:00,  5.64it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 4/8 [00:00<00:00,  4.89it/s]\u001b[A\n",
      " 62%|████████████████████████████▏                | 5/8 [00:01<00:00,  4.53it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 6/8 [00:01<00:00,  4.51it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [00:01<00:00,  3.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 4.141776298638433e-05, 'eval_runtime': 2.0394, 'eval_samples_per_second': 3.923, 'eval_steps_per_second': 3.923, 'eval_rewards/chosen': 2.7093417644500732, 'eval_rewards/rejected': -8.492448806762695, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 11.201790809631348, 'eval_logps/rejected': -125.5295181274414, 'eval_logps/chosen': -67.07902526855469, 'eval_logits/rejected': -5.93147611618042, 'eval_logits/chosen': -5.163938522338867, 'epoch': 13.91}\n",
      " 80%|█████████████████████████████████▌        | 80/100 [05:22<01:16,  3.83s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  3.99it/s]\u001b[A\n",
      "{'loss': 0.0, 'grad_norm': 0.0010266992030665278, 'learning_rate': 0.00040500000000000003, 'rewards/chosen': -0.3000265955924988, 'rewards/rejected': -11.166354179382324, 'rewards/accuracies': 1.0, 'rewards/margins': 10.866328239440918, 'logps/rejected': -180.59210205078125, 'logps/chosen': -117.59622192382812, 'logits/rejected': -4.3525824546813965, 'logits/chosen': -4.331790924072266, 'epoch': 14.09}\n",
      "{'loss': 0.0, 'grad_norm': 0.000932977010961622, 'learning_rate': 0.00041, 'rewards/chosen': 2.393385171890259, 'rewards/rejected': -8.936239242553711, 'rewards/accuracies': 1.0, 'rewards/margins': 11.32962417602539, 'logps/rejected': -140.84912109375, 'logps/chosen': -72.25304412841797, 'logits/rejected': -4.687037467956543, 'logits/chosen': -5.200887680053711, 'epoch': 14.26}\n",
      "{'loss': 0.0, 'grad_norm': 0.000889463524799794, 'learning_rate': 0.000415, 'rewards/chosen': 0.36130574345588684, 'rewards/rejected': -11.734999656677246, 'rewards/accuracies': 1.0, 'rewards/margins': 12.096305847167969, 'logps/rejected': -173.80426025390625, 'logps/chosen': -41.31121063232422, 'logits/rejected': -5.554876327514648, 'logits/chosen': -5.455266952514648, 'epoch': 14.43}\n",
      "{'loss': 0.0, 'grad_norm': 0.0009988696547225118, 'learning_rate': 0.00042, 'rewards/chosen': 0.6952359676361084, 'rewards/rejected': -10.623739242553711, 'rewards/accuracies': 1.0, 'rewards/margins': 11.318976402282715, 'logps/rejected': -169.1638946533203, 'logps/chosen': -140.88418579101562, 'logits/rejected': -4.618934631347656, 'logits/chosen': -5.040587425231934, 'epoch': 14.61}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00124645815230906, 'learning_rate': 0.000425, 'rewards/chosen': 0.4032933712005615, 'rewards/rejected': -10.497358322143555, 'rewards/accuracies': 1.0, 'rewards/margins': 10.900650024414062, 'logps/rejected': -164.823486328125, 'logps/chosen': -115.09419250488281, 'logits/rejected': -3.942579507827759, 'logits/chosen': -4.237168312072754, 'epoch': 14.78}\n",
      "{'loss': 0.0, 'grad_norm': 0.0007763854810036719, 'learning_rate': 0.00043, 'rewards/chosen': 0.7720142602920532, 'rewards/rejected': -10.871871948242188, 'rewards/accuracies': 1.0, 'rewards/margins': 11.643885612487793, 'logps/rejected': -155.86373901367188, 'logps/chosen': -64.63780212402344, 'logits/rejected': -5.242908477783203, 'logits/chosen': -4.7857346534729, 'epoch': 14.96}\n",
      "{'loss': 0.0, 'grad_norm': 0.0007839109166525304, 'learning_rate': 0.000435, 'rewards/chosen': 1.793393850326538, 'rewards/rejected': -10.239521026611328, 'rewards/accuracies': 1.0, 'rewards/margins': 12.032915115356445, 'logps/rejected': -151.23167419433594, 'logps/chosen': -49.846824645996094, 'logits/rejected': -4.763380527496338, 'logits/chosen': -4.639860153198242, 'epoch': 15.13}\n",
      "{'loss': 0.0001, 'grad_norm': 0.001205433625727892, 'learning_rate': 0.00044, 'rewards/chosen': 0.6869844198226929, 'rewards/rejected': -10.467252731323242, 'rewards/accuracies': 1.0, 'rewards/margins': 11.154237747192383, 'logps/rejected': -166.23976135253906, 'logps/chosen': -111.79431915283203, 'logits/rejected': -4.29927396774292, 'logits/chosen': -4.045294284820557, 'epoch': 15.3}\n",
      "{'loss': 0.0, 'grad_norm': 0.00029029062716290355, 'learning_rate': 0.00044500000000000003, 'rewards/chosen': 1.3406614065170288, 'rewards/rejected': -11.896928787231445, 'rewards/accuracies': 1.0, 'rewards/margins': 13.237589836120605, 'logps/rejected': -190.7881317138672, 'logps/chosen': -90.73841857910156, 'logits/rejected': -3.9453041553497314, 'logits/chosen': -4.6430983543396, 'epoch': 15.48}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005999757559038699, 'learning_rate': 0.00045000000000000004, 'rewards/chosen': 0.17423442006111145, 'rewards/rejected': -11.499295234680176, 'rewards/accuracies': 1.0, 'rewards/margins': 11.673529624938965, 'logps/rejected': -185.35397338867188, 'logps/chosen': -109.9569091796875, 'logits/rejected': -4.492671966552734, 'logits/chosen': -4.633134365081787, 'epoch': 15.65}\n",
      " 90%|█████████████████████████████████████▊    | 90/100 [05:59<00:39,  3.95s/it]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 2/8 [00:00<00:00,  6.87it/s]\u001b[A\n",
      " 38%|████████████████▉                            | 3/8 [00:00<00:00,  5.64it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 4/8 [00:00<00:00,  4.89it/s]\u001b[A\n",
      " 62%|████████████████████████████▏                | 5/8 [00:01<00:00,  4.53it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 6/8 [00:01<00:00,  4.51it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [00:01<00:00,  3.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.909048635046929e-05, 'eval_runtime': 2.0383, 'eval_samples_per_second': 3.925, 'eval_steps_per_second': 3.925, 'eval_rewards/chosen': 2.789238452911377, 'eval_rewards/rejected': -8.755681037902832, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 11.544919967651367, 'eval_logps/rejected': -128.16184997558594, 'eval_logps/chosen': -66.28005981445312, 'eval_logits/rejected': -5.980990886688232, 'eval_logits/chosen': -5.178979873657227, 'epoch': 15.65}\n",
      " 90%|█████████████████████████████████████▊    | 90/100 [06:02<00:39,  3.95s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  3.99it/s]\u001b[A\n",
      "{'loss': 0.0, 'grad_norm': 0.0007924034143798053, 'learning_rate': 0.000455, 'rewards/chosen': 1.9273982048034668, 'rewards/rejected': -9.98185920715332, 'rewards/accuracies': 1.0, 'rewards/margins': 11.909258842468262, 'logps/rejected': -146.20132446289062, 'logps/chosen': -49.08186340332031, 'logits/rejected': -4.883273124694824, 'logits/chosen': -5.360024929046631, 'epoch': 15.83}\n",
      "{'loss': 0.0, 'grad_norm': 0.0008522705174982548, 'learning_rate': 0.00046, 'rewards/chosen': 0.4380370080471039, 'rewards/rejected': -10.923505783081055, 'rewards/accuracies': 1.0, 'rewards/margins': 11.361541748046875, 'logps/rejected': -154.0514678955078, 'logps/chosen': -100.9864501953125, 'logits/rejected': -4.337696075439453, 'logits/chosen': -4.093508243560791, 'epoch': 16.0}\n",
      "{'loss': 0.0, 'grad_norm': 0.000683248566929251, 'learning_rate': 0.000465, 'rewards/chosen': 1.0660209655761719, 'rewards/rejected': -9.97681999206543, 'rewards/accuracies': 1.0, 'rewards/margins': 11.042840957641602, 'logps/rejected': -157.64776611328125, 'logps/chosen': -75.75312805175781, 'logits/rejected': -4.605857849121094, 'logits/chosen': -4.482243537902832, 'epoch': 16.17}\n",
      "{'loss': 0.0, 'grad_norm': 0.0010501178912818432, 'learning_rate': 0.00047, 'rewards/chosen': 1.382775902748108, 'rewards/rejected': -9.608368873596191, 'rewards/accuracies': 1.0, 'rewards/margins': 10.991144180297852, 'logps/rejected': -151.27928161621094, 'logps/chosen': -88.60350036621094, 'logits/rejected': -4.26448392868042, 'logits/chosen': -4.231368064880371, 'epoch': 16.35}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006849723868072033, 'learning_rate': 0.000475, 'rewards/chosen': 0.878848135471344, 'rewards/rejected': -10.944292068481445, 'rewards/accuracies': 1.0, 'rewards/margins': 11.823141098022461, 'logps/rejected': -150.61923217773438, 'logps/chosen': -91.07443237304688, 'logits/rejected': -5.065783500671387, 'logits/chosen': -5.031705856323242, 'epoch': 16.52}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005447968724183738, 'learning_rate': 0.00048, 'rewards/chosen': 1.1497997045516968, 'rewards/rejected': -10.827823638916016, 'rewards/accuracies': 1.0, 'rewards/margins': 11.977622032165527, 'logps/rejected': -168.9626007080078, 'logps/chosen': -78.73505401611328, 'logits/rejected': -3.930614709854126, 'logits/chosen': -3.6218669414520264, 'epoch': 16.7}\n",
      "{'loss': 0.0, 'grad_norm': 0.0004970906302332878, 'learning_rate': 0.00048499999999999997, 'rewards/chosen': -0.24034905433654785, 'rewards/rejected': -13.474981307983398, 'rewards/accuracies': 1.0, 'rewards/margins': 13.23463249206543, 'logps/rejected': -206.53045654296875, 'logps/chosen': -94.41615295410156, 'logits/rejected': -4.999391555786133, 'logits/chosen': -5.703061580657959, 'epoch': 16.87}\n",
      "{'loss': 0.0, 'grad_norm': 0.00034483810304664075, 'learning_rate': 0.00049, 'rewards/chosen': 1.614814281463623, 'rewards/rejected': -11.839298248291016, 'rewards/accuracies': 1.0, 'rewards/margins': 13.454113006591797, 'logps/rejected': -173.5120849609375, 'logps/chosen': -63.27295684814453, 'logits/rejected': -5.161815643310547, 'logits/chosen': -5.358639717102051, 'epoch': 17.04}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006059266161173582, 'learning_rate': 0.000495, 'rewards/chosen': 1.8555498123168945, 'rewards/rejected': -10.4336519241333, 'rewards/accuracies': 1.0, 'rewards/margins': 12.289200782775879, 'logps/rejected': -173.36062622070312, 'logps/chosen': -96.5749282836914, 'logits/rejected': -3.138807535171509, 'logits/chosen': -3.7775940895080566, 'epoch': 17.22}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005500703118741512, 'learning_rate': 0.0005, 'rewards/chosen': 1.71293044090271, 'rewards/rejected': -9.737564086914062, 'rewards/accuracies': 1.0, 'rewards/margins': 11.450493812561035, 'logps/rejected': -151.17457580566406, 'logps/chosen': -96.91548919677734, 'logits/rejected': -4.9075398445129395, 'logits/chosen': -4.483463287353516, 'epoch': 17.39}\n",
      "100%|█████████████████████████████████████████| 100/100 [06:40<00:00,  3.89s/it]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 2/8 [00:00<00:00,  6.88it/s]\u001b[A\n",
      " 38%|████████████████▉                            | 3/8 [00:00<00:00,  5.64it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 4/8 [00:00<00:00,  4.89it/s]\u001b[A\n",
      " 62%|████████████████████████████▏                | 5/8 [00:01<00:00,  4.53it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 6/8 [00:01<00:00,  4.51it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [00:01<00:00,  3.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.2660127797280438e-05, 'eval_runtime': 2.0393, 'eval_samples_per_second': 3.923, 'eval_steps_per_second': 3.923, 'eval_rewards/chosen': 2.8275465965270996, 'eval_rewards/rejected': -8.965958595275879, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 11.793503761291504, 'eval_logps/rejected': -130.26461791992188, 'eval_logps/chosen': -65.89698028564453, 'eval_logits/rejected': -5.981106758117676, 'eval_logits/chosen': -5.1661810874938965, 'epoch': 17.39}\n",
      "100%|█████████████████████████████████████████| 100/100 [06:42<00:00,  3.89s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  3.99it/s]\u001b[A\n",
      "                                                                                \u001b[A/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in ./merged-sft - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "{'train_runtime': 403.1451, 'train_samples_per_second': 2.977, 'train_steps_per_second': 0.248, 'train_loss': 0.11033511952953631, 'epoch': 17.39}\n",
      "100%|█████████████████████████████████████████| 100/100 [06:43<00:00,  4.03s/it]\n",
      "***** train metrics *****\n",
      "  epoch                    =      17.39\n",
      "  train_loss               =     0.1103\n",
      "  train_runtime            = 0:06:43.14\n",
      "  train_samples            =        100\n",
      "  train_samples_per_second =      2.977\n",
      "  train_steps_per_second   =      0.248\n",
      "\u001b[32m2024-03-14 13:53:33.921\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m479\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 403.1451, 'train_samples_per_second': 2.977, 'train_steps_per_second': 0.248, 'train_loss': 0.11033511952953631, 'epoch': 17.39, 'train_samples': 100}\u001b[0m\n",
      "\u001b[32m2024-03-14 13:53:33.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m480\u001b[0m - \u001b[1mSaving model checkpoint to outputs-dpo-v1\u001b[0m\n",
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in ./merged-sft - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-03-14 13:53:34.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m487\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  4.43it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =      17.39\n",
      "  eval_logits/chosen      =    -5.1662\n",
      "  eval_logits/rejected    =    -5.9811\n",
      "  eval_logps/chosen       =    -65.897\n",
      "  eval_logps/rejected     =  -130.2646\n",
      "  eval_loss               =        0.0\n",
      "  eval_rewards/accuracies =        1.0\n",
      "  eval_rewards/chosen     =     2.8275\n",
      "  eval_rewards/margins    =    11.7935\n",
      "  eval_rewards/rejected   =     -8.966\n",
      "  eval_runtime            = 0:00:02.03\n",
      "  eval_samples            =         10\n",
      "  eval_samples_per_second =      3.937\n",
      "  eval_steps_per_second   =      3.937\n",
      "\u001b[32m2024-03-14 13:53:36.422\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m493\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 2.2660127797280438e-05, 'eval_runtime': 2.0322, 'eval_samples_per_second': 3.937, 'eval_steps_per_second': 3.937, 'eval_rewards/chosen': 2.8275465965270996, 'eval_rewards/rejected': -8.965958595275879, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 11.793503761291504, 'eval_logps/rejected': -130.26461791992188, 'eval_logps/chosen': -65.89698028564453, 'eval_logits/rejected': -5.981106758117676, 'eval_logits/chosen': -5.1661810874938965, 'epoch': 17.39, 'eval_samples': 10}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1 python dpo_training.py \\\n",
    "    --model_type baichuan \\\n",
    "    --model_name_or_path ./merged-sft \\\n",
    "    --train_file_dir ./data/reward \\\n",
    "    --validation_file_dir ./data/reward \\\n",
    "    --per_device_train_batch_size 3 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --use_peft True \\\n",
    "    --max_train_samples 1000 \\\n",
    "    --max_eval_samples 10 \\\n",
    "    --max_steps 100 \\\n",
    "    --eval_steps 10 \\\n",
    "    --save_steps 50 \\\n",
    "    --max_source_length 128 \\\n",
    "    --max_target_length 128 \\\n",
    "    --output_dir outputs-dpo-v1 \\\n",
    "    --target_modules all \\\n",
    "    --lora_rank 8 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --torch_dtype float16 \\\n",
    "    --fp16 True \\\n",
    "    --device_map auto \\\n",
    "    --report_to tensorboard \\\n",
    "    --remove_unused_columns False \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --cache_dir ./cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 71M\n",
      "-rw-r--r-- 1 root root  659 Mar 14 13:53 adapter_config.json\n",
      "-rw-r--r-- 1 root root  69M Mar 14 13:53 adapter_model.safetensors\n",
      "-rw-r--r-- 1 root root  729 Mar 14 13:53 all_results.json\n",
      "drwxr-xr-x 2 root root  310 Mar 14 13:53 \u001b[0m\u001b[01;34mcheckpoint-100\u001b[0m/\n",
      "drwxr-xr-x 2 root root  310 Mar 14 13:50 \u001b[01;34mcheckpoint-50\u001b[0m/\n",
      "-rw-r--r-- 1 root root  557 Mar 14 13:53 eval_results.json\n",
      "-rw-r--r-- 1 root root 5.0K Mar 14 13:53 README.md\n",
      "drwxr-xr-x 3 root root   58 Mar 14 13:46 \u001b[01;34mruns\u001b[0m/\n",
      "-rw-r--r-- 1 root root  548 Mar 14 13:53 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root 9.8K Mar 14 13:53 tokenization_baichuan.py\n",
      "-rw-r--r-- 1 root root  942 Mar 14 13:53 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 2.0M Mar 14 13:53 tokenizer.model\n",
      "-rw-r--r-- 1 root root  55K Mar 14 13:53 trainer_state.json\n",
      "-rw-r--r-- 1 root root 4.9K Mar 14 13:53 training_args.bin\n",
      "-rw-r--r-- 1 root root  194 Mar 14 13:53 train_results.json\n"
     ]
    }
   ],
   "source": [
    "%ls -lh outputs-dpo-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "模型训练结果：\n",
    "- 使用lora训练模型，则保存的lora权重是`adapter_model.bin`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
    "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_type='baichuan', base_model='merged-sft', tokenizer_path=None, lora_model='outputs-dpo-v1', resize_emb=False, output_dir='merged-dpo/')\n",
      "Base model: merged-sft\n",
      "LoRA model: outputs-dpo-v1\n",
      "Loading LoRA for causal language model\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:05<00:00,  1.30s/it]\n",
      "Merging with merge_and_unload...\n",
      "Saving to Hugging Face format...\n",
      "Done! model saved to merged-dpo/\n"
     ]
    }
   ],
   "source": [
    "!python merge_peft_adapter.py --model_type baichuan \\\n",
    "    --base_model merged-sft --lora_model outputs-dpo-v1 --output_dir merged-dpo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14G\n",
      "-rw-r--r-- 1 root root  812 Mar 14 15:10 config.json\n",
      "-rw-r--r-- 1 root root 2.4K Mar 14 15:10 configuration_baichuan.py\n",
      "-rw-r--r-- 1 root root  285 Mar 14 15:10 generation_config.json\n",
      "-rw-r--r-- 1 root root 2.9K Mar 14 15:10 generation_utils.py\n",
      "-rw-r--r-- 1 root root  33K Mar 14 15:10 modeling_baichuan.py\n",
      "-rw-r--r-- 1 root root 4.7G Mar 14 15:10 pytorch_model-00001-of-00004.bin\n",
      "-rw-r--r-- 1 root root 4.7G Mar 14 15:10 pytorch_model-00002-of-00004.bin\n",
      "-rw-r--r-- 1 root root 3.8G Mar 14 15:11 pytorch_model-00003-of-00004.bin\n",
      "-rw-r--r-- 1 root root 983M Mar 14 15:11 pytorch_model-00004-of-00004.bin\n",
      "-rw-r--r-- 1 root root  19K Mar 14 15:11 pytorch_model.bin.index.json\n",
      "-rw-r--r-- 1 root root 8.9K Mar 14 15:10 quantizer.py\n",
      "-rw-r--r-- 1 root root  548 Mar 14 15:10 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root 9.8K Mar 14 15:10 tokenization_baichuan.py\n",
      "-rw-r--r-- 1 root root  942 Mar 14 15:10 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 2.0M Mar 14 15:10 tokenizer.model\n"
     ]
    }
   ],
   "source": [
    "%ls -lh merged-dpo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_from_model_config\": true,\n",
      "  \"_name_or_path\": \"merged-sft\",\n",
      "  \"architectures\": [\n",
      "    \"BaichuanForCausalLM\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_baichuan.BaichuanConfig\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_baichuan.BaichuanForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"baichuan\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"BaichuanTokenizer\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.38.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 125696,\n",
      "  \"z_loss_weight\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%cat merged-dpo/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Stage3 偏好建模第一次训练完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**至此一个完整的训练流程演示完成。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T12:34:29.658428Z",
     "start_time": "2023-06-26T12:34:29.620609Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T12:35:00.864463Z",
     "start_time": "2023-06-26T12:34:47.802087Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!python inference.py --model_type baichuan --base_model merged-dpo --interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Input:介绍下南京\n",
    "Response:  南京市位于江苏省西南部，是全国首批历史文化名城、国家中心城市和自由贸易试验区。\n",
    "\n",
    "完。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_gpt",
   "language": "python",
   "name": "medical_gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f34eed0bebedfc4b6ee51ced43d2c030fe3b92f13c149d072205ca200a67b1ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
