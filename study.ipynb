{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd18580-69ca-41df-9d60-5337a90f8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f91475d7-7f8a-43d0-892b-f0e9c9a713e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BloomForCausalLM,\n",
    "    BloomTokenizerFast,\n",
    "    LlamaTokenizer,\n",
    "    LlamaForCausalLM,\n",
    "    TextIteratorStreamer,\n",
    "    GenerationConfig,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d91764-2b96-4b57-92db-bec08ea51867",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    \"bloom\": (BloomForCausalLM, BloomTokenizerFast),\n",
    "    \"chatglm\": (AutoModel, AutoTokenizer),\n",
    "    \"llama\": (LlamaForCausalLM, LlamaTokenizer),\n",
    "    \"baichuan\": (AutoModelForCausalLM, AutoTokenizer),\n",
    "    \"auto\": (AutoModelForCausalLM, AutoTokenizer),\n",
    "}\n",
    "model_class, tokenizer_class = MODEL_CLASSES[\"baichuan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85740ab5-74c3-43de-b3b7-1986cdc43859",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/fashion_mnist_experiment_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ead1157c-c613-4811-9115-dceaf835368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = \"merged-dpo\"\n",
    "base_model = \"/data/jupyter_multi_users/tengzhiyong/share/model/baichuan2-7b-chat\"\n",
    "load_type  = torch.float16\n",
    "base_model = model_class.from_pretrained(\n",
    "    base_model,\n",
    "    torch_dtype=load_type,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map='auto',\n",
    "    trust_remote_code=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9116b1ba-5141-4609-a247-e3f86b96f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randint(2, 1000, (1, 512), dtype=torch.long, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a87b3d75-5e35-4f33-8466-5ac0e876c9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_kwarg_inputs should be a dict\n",
      "Error occurs, No graph saved\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "example_kwarg_inputs should be a dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 创建一个dummy input，其大小需要与你模型的输入大小相匹配\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py:889\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[0;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    885\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;66;03m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_graph(\n\u001b[0;32m--> 889\u001b[0m         \u001b[43mgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_to_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;66;03m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m caffe2_pb2\n",
      "File \u001b[0;32m/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/tensorboard/_pytorch_graph.py:336\u001b[0m, in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurs, No graph saved\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 336\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mprint\u001b[39m(graph)\n",
      "File \u001b[0;32m/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/utils/tensorboard/_pytorch_graph.py:330\u001b[0m, in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _set_model_to_eval(model):\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m         trace \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m         graph \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mgraph\n\u001b[1;32m    332\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_inline(graph)\n",
      "File \u001b[0;32m/data/apps/conda/envs/medical_gpt/lib/python3.10/site-packages/torch/jit/_trace.py:805\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    803\u001b[0m             example_inputs \u001b[38;5;241m=\u001b[39m example_kwarg_inputs\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 805\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    807\u001b[0m         func,\n\u001b[1;32m    808\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    817\u001b[0m         _store_inputs\u001b[38;5;241m=\u001b[39m_store_inputs,\n\u001b[1;32m    818\u001b[0m     )\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    823\u001b[0m ):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: example_kwarg_inputs should be a dict"
     ]
    }
   ],
   "source": [
    "# 创建一个dummy input，其大小需要与你模型的输入大小相匹配\n",
    "writer.add_graph(base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6b98707-dd2b-4e24-9c4c-8e1db81a1945",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73881f7a-44bf-4acf-8ab1-db1dda9e3a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_gpt",
   "language": "python",
   "name": "medical_gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
